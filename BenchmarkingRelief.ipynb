{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5fcbaf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galynch/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "/home/galynch/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GPU detected. Including GPU benchmarks.\n",
      "\n",
      "--- Warming up JIT compilers ---\n",
      "  Warming up fast_relief.ReliefF (CPU)...\n",
      "Running ReliefF on the CPU now...\n",
      "  Warming up fast_relief.MultiSURF (CPU)...\n",
      "  Warming up fast_relief.ReliefF (GPU)...\n",
      "  Warming up fast_relief.MultiSURF (GPU)...\n",
      "--- Warm-up complete ---\n",
      "\n",
      "--- Running Scenario: p >> n ---\n",
      "\n",
      "Generating data: 100 samples, 100000 features\n",
      "  Benchmarking fast_relief.ReliefF (CPU) (Run 1/1)...\n",
      "Running ReliefF on the CPU now...\n",
      "  Benchmarking fast_relief.MultiSURF (CPU) (Run 1/1)...\n",
      "  Benchmarking fast_relief.ReliefF (GPU) (Run 1/1)...\n",
      "  Benchmarking fast_relief.MultiSURF (GPU) (Run 1/1)...\n",
      "\n",
      "Generating data: 100 samples, 200000 features\n",
      "  Benchmarking fast_relief.ReliefF (CPU) (Run 1/1)...\n",
      "Running ReliefF on the CPU now...\n",
      "  Benchmarking fast_relief.MultiSURF (CPU) (Run 1/1)...\n",
      "  Benchmarking fast_relief.ReliefF (GPU) (Run 1/1)...\n",
      "  Benchmarking fast_relief.MultiSURF (GPU) (Run 1/1)...\n",
      "\n",
      "Generating data: 100 samples, 300000 features\n",
      "  Benchmarking fast_relief.ReliefF (CPU) (Run 1/1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process MemTimer-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/galynch/.local/lib/python3.10/site-packages/memory_profiler.py\", line 262, in run\n",
      "    stop = self.pipe.poll(self.interval)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 424, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3756576/222058142.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;31m# Best practice is to have your script execute via a main function call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;31m# Clean up NVML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3756576/222058142.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                             \u001b[0mis_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"(GPU)\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mest_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                             \u001b[0mruntime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_single_benchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m                             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"scenario\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"algorithm\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mest_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_features\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"runtime\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_increase_mb\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmemory_mb\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3756576/222058142.py\u001b[0m in \u001b[0;36mrun_single_benchmark\u001b[0;34m(estimator, X, y, is_gpu)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mmem_profile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mmem_increase_mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_profile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmem_profile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/memory_profiler.py\u001b[0m in \u001b[0;36mmemory_usage\u001b[0;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend, max_iterations)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;31m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0mreturned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m                 \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# finish timing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3756576/222058142.py\u001b[0m in \u001b[0;36mfit_estimator\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mmem_increase_mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_gpu\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mGPU_AVAILABLE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpynvml_available\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/snap/snapd-desktop-integration/253/Desktop/FastRelief/src/fast_select/ReliefF.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mis_discrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscrete_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0mis_discrete\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         ret = _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0m\u001b[1;32m    275\u001b[0m                         equal_nan=equal_nan)\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     if (equal_nan and aux.shape[0] > 0 and aux.dtype.kind in \"cfmM\" and\n\u001b[0;32m--> 341\u001b[0;31m             np.isnan(aux[-1])):\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for complex all NaNs are considered equivalent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0maux_firstnan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import make_classification\n",
    "import threading\n",
    "import os\n",
    "\n",
    "# --- Plotting Libraries ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Profiling and Estimator Libraries ---\n",
    "from memory_profiler import memory_usage\n",
    "try:\n",
    "    from pynvml import *\n",
    "    pynvml_available = True\n",
    "except ImportError:\n",
    "    pynvml_available = False\n",
    "\n",
    "from skrebate import ReliefF, SURF, SURFstar, MultiSURF as SkrebateMultiSURF, MultiSURFstar\n",
    "# Assuming your local implementations are in a 'src' directory\n",
    "from src.fast_select.ReliefF import ReliefF as FastReliefF\n",
    "from src.fast_select.SURF import SURF as FastSURF\n",
    "from src.fast_select.MultiSURF import MultiSURF as FastMultiSURF\n",
    "\n",
    "try:\n",
    "    from numba import cuda\n",
    "    GPU_AVAILABLE = cuda.is_available()\n",
    "    if pynvml_available and GPU_AVAILABLE:\n",
    "        nvmlInit()\n",
    "except (ImportError, NVMLError):\n",
    "    GPU_AVAILABLE = False\n",
    "\n",
    "# --- Benchmark Configuration ---\n",
    "P_DOMINANT_SCENARIOS = { \"n_samples\": 100, \"n_features_range\": [100000, 200000, 300000, 400000, 500000] }\n",
    "N_DOMINANT_SCENARIOS = { \"n_features\": 100, \"n_samples_range\": [10000, 20000, 30000, 40000, 50000] }\n",
    "N_FEATURES_TO_SELECT = 10\n",
    "N_REPEATS = 1 # Increased repeats for more stable averages in plots\n",
    "\n",
    "# --- Estimators to Test ---\n",
    "estimators = {\n",
    "    #\"skrebate.ReliefF\": ReliefF(n_features_to_select=N_FEATURES_TO_SELECT, n_jobs=-1),\n",
    "    #\"skrebate.MultiSURF\": SkrebateMultiSURF(n_features_to_select=N_FEATURES_TO_SELECT, n_jobs=-1),\n",
    "    \"fast_relief.ReliefF (CPU)\": FastReliefF(n_features_to_select=N_FEATURES_TO_SELECT, backend='cpu', verbose=True),\n",
    "    \"fast_relief.MultiSURF (CPU)\": FastMultiSURF(n_features_to_select=N_FEATURES_TO_SELECT, backend='cpu'),\n",
    "}\n",
    "if GPU_AVAILABLE:\n",
    "    print(\"NVIDIA GPU detected. Including GPU benchmarks.\")\n",
    "    estimators.update({\n",
    "        \"fast_relief.ReliefF (GPU)\": FastReliefF(n_features_to_select=N_FEATURES_TO_SELECT, backend='gpu'),\n",
    "        \"fast_relief.MultiSURF (GPU)\": FastMultiSURF(n_features_to_select=N_FEATURES_TO_SELECT, backend='gpu'),\n",
    "    })\n",
    "else:\n",
    "    print(\"No NVIDIA GPU detected. Skipping GPU benchmarks.\")\n",
    "\n",
    "\n",
    "# --- CORE BENCHMARKING FUNCTIONS (with memory profiling) ---\n",
    "def run_single_benchmark(estimator, X, y, is_gpu=False):\n",
    "    mem_increase_mb = -1.0\n",
    "    def fit_estimator():\n",
    "        estimator.fit(X, y)\n",
    "\n",
    "    if is_gpu and GPU_AVAILABLE and pynvml_available:\n",
    "        handle = nvmlDeviceGetHandleByIndex(0)\n",
    "        class MemTracker(threading.Thread):\n",
    "            def __init__(self):\n",
    "                threading.Thread.__init__(self)\n",
    "                self.peak_mem = 0\n",
    "                self.running = True\n",
    "            def run(self):\n",
    "                initial_mem = nvmlDeviceGetMemoryInfo(handle).used\n",
    "                while self.running:\n",
    "                    self.peak_mem = max(self.peak_mem, nvmlDeviceGetMemoryInfo(handle).used - initial_mem)\n",
    "                    time.sleep(0.01)\n",
    "            def stop(self):\n",
    "                self.running = False\n",
    "        tracker = MemTracker()\n",
    "        tracker.start()\n",
    "        start_time = time.perf_counter()\n",
    "        try:\n",
    "            fit_estimator()\n",
    "        finally:\n",
    "            tracker.stop()\n",
    "            tracker.join()\n",
    "        end_time = time.perf_counter()\n",
    "        mem_increase_mb = tracker.peak_mem / (1024**2)\n",
    "    else:\n",
    "        start_time = time.perf_counter()\n",
    "        mem_profile, _ = memory_usage((fit_estimator,), retval=True, interval=0.1)\n",
    "        end_time = time.perf_counter()\n",
    "        mem_increase_mb = max(mem_profile) - mem_profile[0]\n",
    "        \n",
    "    runtime = end_time - start_time\n",
    "    return runtime, mem_increase_mb\n",
    "\n",
    "def warmup_jit_compilers(estimators_dict):\n",
    "    print(\"\\n--- Warming up JIT compilers ---\")\n",
    "    X_warmup, y_warmup = make_classification(n_samples=10, n_features=10, random_state=42)\n",
    "    for name, estimator in estimators_dict.items():\n",
    "        if \"fast_relief\" in name:\n",
    "            print(f\"  Warming up {name}...\")\n",
    "            try:\n",
    "                clone(estimator).fit(X_warmup, y_warmup)\n",
    "            except Exception as e:\n",
    "                warnings.warn(f\"  > Warm-up FAILED for {name}. Reason: {e}\")\n",
    "    print(\"--- Warm-up complete ---\")\n",
    "\n",
    "\n",
    "def plot_scenario(df, scenario_name, x_axis, y_axis, title, filename):\n",
    "    \"\"\"\n",
    "    Generates and saves a line plot for a given benchmark scenario.\n",
    "    Handles potential pandas/matplotlib version conflicts automatically.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    scenario_df = df[df['scenario'] == scenario_name]\n",
    "\n",
    "    # Use seaborn for a clean, publication-quality line plot\n",
    "    # It automatically groups by 'algorithm' and calculates mean/confidence intervals\n",
    "    sns.lineplot(\n",
    "        data=scenario_df,\n",
    "        x=x_axis,\n",
    "        y=y_axis,\n",
    "        hue='algorithm',\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        errorbar=('ci', 95) # Show 95% confidence interval\n",
    "    )\n",
    "\n",
    "    # Adding plot labels and title\n",
    "    plt.title(title, fontsize=18, fontweight='bold')\n",
    "    plt.xlabel(x_axis.replace('_', ' ').title(), fontsize=14)\n",
    "    plt.ylabel(y_axis.replace('_', ' ').title(), fontsize=14)\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.legend(title='Algorithm', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make space for legend\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Plot saved to '{filename}'\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- MAIN EXECUTION BLOCK ---\n",
    "def main():\n",
    "    \"\"\"Main function to run all benchmark scenarios and generate plots.\"\"\"\n",
    "    results = []\n",
    "    output_dir = \"benchmark_plots\"\n",
    "    os.makedirs(output_dir, exist_ok=True) # Create directory for plots\n",
    "\n",
    "    warmup_jit_compilers(estimators)\n",
    "\n",
    "    # --- Run Benchmark Scenarios ---\n",
    "    scenarios = {\n",
    "        \"p >> n\": (P_DOMINANT_SCENARIOS, \"n_features\"),\n",
    "        \"n >> p\": (N_DOMINANT_SCENARIOS, \"n_samples\")\n",
    "    }\n",
    "\n",
    "    for name, (params, independent_var) in scenarios.items():\n",
    "        print(f\"\\n--- Running Scenario: {name} ---\")\n",
    "        if name == \"p >> n\":\n",
    "            param_range = params[\"n_features_range\"]\n",
    "            n_samples = params[\"n_samples\"]\n",
    "            for n_features in param_range:\n",
    "                print(f\"\\nGenerating data: {n_samples} samples, {n_features} features\")\n",
    "                X, y = make_classification(n_samples=n_samples, n_features=n_features, n_informative=20, n_redundant=100, random_state=42)\n",
    "                for est_name, estimator in estimators.items():\n",
    "                    for i in range(N_REPEATS):\n",
    "                        print(f\"  Benchmarking {est_name} (Run {i+1}/{N_REPEATS})...\")\n",
    "                        try:\n",
    "                            is_gpu = \"(GPU)\" in est_name\n",
    "                            runtime, memory_mb = run_single_benchmark(clone(estimator), X, y, is_gpu)\n",
    "                            results.append({\"scenario\": name, \"algorithm\": est_name, \"n_samples\": n_samples, \"n_features\": n_features, \"runtime\": runtime, \"memory_increase_mb\": memory_mb})\n",
    "                        except Exception as e:\n",
    "                            warnings.warn(f\"  > FAILED: {est_name}. Reason: {e}\")\n",
    "        else: # n >> p\n",
    "            param_range = params[\"n_samples_range\"]\n",
    "            n_features = params[\"n_features\"]\n",
    "            for n_samples in param_range:\n",
    "                print(f\"\\nGenerating data: {n_samples} samples, {n_features} features\")\n",
    "                X, y = make_classification(n_samples=n_samples, n_features=n_features, n_informative=20, n_redundant=50, random_state=42)\n",
    "                for est_name, estimator in estimators.items():\n",
    "                    for i in range(N_REPEATS):\n",
    "                        print(f\"  Benchmarking {est_name} (Run {i+1}/{N_REPEATS})...\")\n",
    "                        try:\n",
    "                            is_gpu = \"(GPU)\" in est_name\n",
    "                            runtime, memory_mb = run_single_benchmark(clone(estimator), X, y, is_gpu)\n",
    "                            results.append({\"scenario\": name, \"algorithm\": est_name, \"n_samples\": n_samples, \"n_features\": n_features, \"runtime\": runtime, \"memory_increase_mb\": memory_mb})\n",
    "                        except Exception as e:\n",
    "                            warnings.warn(f\"  > FAILED: {est_name}. Reason: {e}\")\n",
    "    \n",
    "    # --- Save results to CSV ---\n",
    "    df = pd.DataFrame(results)\n",
    "    output_file = \"benchmark_results_with_memory.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nBenchmarking complete. Results saved to '{output_file}'\")\n",
    "\n",
    "    # --- Generate and Save Plots ---\n",
    "    print(\"\\n--- Generating Plots ---\")\n",
    "    \n",
    "    # Plot 1: Runtime for p >> n\n",
    "    plot_scenario(df, 'p >> n', 'n_features', 'runtime', \n",
    "                  'Runtime Performance (Many Features, p >> n)', \n",
    "                  os.path.join(output_dir, 'p_dominant_runtime.png'))\n",
    "\n",
    "    # Plot 2: Memory for p >> n\n",
    "    plot_scenario(df, 'p >> n', 'n_features', 'memory_increase_mb', \n",
    "                  'Memory Usage (Many Features, p >> n)', \n",
    "                  os.path.join(output_dir, 'p_dominant_memory.png'))\n",
    "\n",
    "    # Plot 3: Runtime for n >> p\n",
    "    plot_scenario(df, 'n >> p', 'n_samples', 'runtime', \n",
    "                  'Runtime Performance (Many Samples, n >> p)', \n",
    "                  os.path.join(output_dir, 'n_dominant_runtime.png'))\n",
    "\n",
    "    # Plot 4: Memory for n >> p\n",
    "    plot_scenario(df, 'n >> p', 'n_samples', 'memory_increase_mb', \n",
    "                  'Memory Usage (Many Samples, n >> p)', \n",
    "                  os.path.join(output_dir, 'n_dominant_memory.png'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Best practice is to have your script execute via a main function call\n",
    "    main()\n",
    "    \n",
    "    # Clean up NVML\n",
    "    if GPU_AVAILABLE and pynvml_available:\n",
    "        try:\n",
    "            nvmlShutdown()\n",
    "        except NVMLError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05174a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 4cf720a] getting tests and CI/CD working\n",
      " 1 file changed, 2 deletions(-)\n",
      "Enumerating objects: 9, done.\n",
      "Counting objects: 100% (9/9), done.\n",
      "Delta compression using up to 20 threads\n",
      "Compressing objects: 100% (5/5), done.\n",
      "Writing objects: 100% (5/5), 452 bytes | 452.00 KiB/s, done.\n",
      "Total 5 (delta 3), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
      "To https://github.com/GavinLynch04/FastSelect.git\n",
      "   4020dd9..4cf720a  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git commit -a -m \"getting tests and CI/CD working\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d2c79e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\r\n",
      "Your branch is up to date with 'origin/main'.\r\n",
      "\r\n",
      "Changes to be committed:\r\n",
      "  (use \"git restore --staged <file>...\" to unstage)\r\n",
      "\t\u001b[32mmodified:   BenchmarkingRelief.ipynb\u001b[m\r\n",
      "\t\u001b[32mmodified:   __init__.py\u001b[m\r\n",
      "\t\u001b[32mmodified:   tests/test_chi2.py\u001b[m\r\n",
      "\t\u001b[32mmodified:   tests/test_relieff.py\u001b[m\r\n",
      "\t\u001b[32mmodified:   tests/test_surf.py\u001b[m\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\r\n",
      "\t\u001b[31mmodified:   BenchmarkingRelief.ipynb\u001b[m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bae9eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7818c054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 6, done.\u001b[K\r\n",
      "remote: Counting objects:  16% (1/6)\u001b[K\r",
      "remote: Counting objects:  33% (2/6)\u001b[K\r",
      "remote: Counting objects:  50% (3/6)\u001b[K\r",
      "remote: Counting objects:  66% (4/6)\u001b[K\r",
      "remote: Counting objects:  83% (5/6)\u001b[K\r",
      "remote: Counting objects: 100% (6/6)\u001b[K\r",
      "remote: Counting objects: 100% (6/6), done.\u001b[K\r\n",
      "remote: Compressing objects:  33% (1/3)\u001b[K\r",
      "remote: Compressing objects:  66% (2/3)\u001b[K\r",
      "remote: Compressing objects: 100% (3/3)\u001b[K\r",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\r\n",
      "remote: Total 5 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\r\n",
      "Unpacking objects:  20% (1/5)\r",
      "Unpacking objects:  40% (2/5)\r",
      "Unpacking objects:  60% (3/5)\r",
      "Unpacking objects:  80% (4/5)\r",
      "Unpacking objects: 100% (5/5)\r",
      "Unpacking objects: 100% (5/5), 1.94 KiB | 991.00 KiB/s, done.\r\n",
      "From https://github.com/GavinLynch04/FastSelect\r\n",
      "   43df5fb..55dbf04  main       -> origin/main\r\n",
      "Updating 43df5fb..55dbf04\r\n",
      "Fast-forward\r\n",
      " .github/workflows/python-tests.yml | 61 \u001b[32m++++++++++++++++++++++++++++++++++++++\u001b[m\r\n",
      " 1 file changed, 61 insertions(+)\r\n",
      " create mode 100644 .github/workflows/python-tests.yml\r\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b47e701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
