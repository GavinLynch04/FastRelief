{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5fcbaf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galynch/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "/home/galynch/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GPU detected. Including GPU benchmarks.\n",
      "\n",
      "--- Warming up JIT compilers ---\n",
      "  Warming up fast_relief.ReliefF (CPU)...\n",
      "  Warming up fast_relief.MultiSURF (CPU)...\n",
      "  Warming up fast_relief.ReliefF (GPU)...\n",
      "Running ReliefF on the GPU now...\n",
      "  Warming up fast_relief.MultiSURF (GPU)...\n",
      "--- Warm-up complete ---\n",
      "\n",
      "--- Running Scenario: p >> n ---\n",
      "\n",
      "Generating data: 100 samples, 100000 features\n",
      "  Benchmarking fast_relief.ReliefF (CPU) (Run 1/1)...\n",
      "  Benchmarking fast_relief.MultiSURF (CPU) (Run 1/1)...\n",
      "  Benchmarking fast_relief.ReliefF (GPU) (Run 1/1)...\n",
      "Running ReliefF on the GPU now...\n",
      "  Benchmarking fast_relief.MultiSURF (GPU) (Run 1/1)...\n",
      "\n",
      "Generating data: 100 samples, 200000 features\n",
      "  Benchmarking fast_relief.ReliefF (CPU) (Run 1/1)...\n",
      "  Benchmarking fast_relief.MultiSURF (CPU) (Run 1/1)...\n",
      "  Benchmarking fast_relief.ReliefF (GPU) (Run 1/1)...\n",
      "Running ReliefF on the GPU now...\n",
      "  Benchmarking fast_relief.MultiSURF (GPU) (Run 1/1)...\n",
      "\n",
      "Generating data: 100 samples, 300000 features\n",
      "  Benchmarking fast_relief.ReliefF (CPU) (Run 1/1)...\n",
      "  Benchmarking fast_relief.MultiSURF (CPU) (Run 1/1)...\n",
      "  Benchmarking fast_relief.ReliefF (GPU) (Run 1/1)...\n",
      "Running ReliefF on the GPU now...\n",
      "  Benchmarking fast_relief.MultiSURF (GPU) (Run 1/1)...\n",
      "\n",
      "Generating data: 100 samples, 400000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_3755788/222058142.py\", line 224, in <module>\n",
      "    main()\n",
      "  File \"/tmp/ipykernel_3755788/222058142.py\", line 167, in main\n",
      "    X, y = make_classification(n_samples=n_samples, n_features=n_features, n_informative=20, n_redundant=100, random_state=42)\n",
      "  File \"/home/galynch/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/galynch/.local/lib/python3.10/site-packages/sklearn/datasets/_samples_generator.py\", line 318, in make_classification\n",
      "    X[:, -n_random:] = generator.standard_normal(size=(n_samples, n_random))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
      "    module = getmodule(object, filename)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 878, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.10/posixpath.py\", line 396, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, strict, {})\n",
      "  File \"/usr/lib/python3.10/posixpath.py\", line 429, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/usr/lib/python3.10/posixpath.py\", line 77, in join\n",
      "    sep = _get_sep(a)\n",
      "  File \"/usr/lib/python3.10/posixpath.py\", line 42, in _get_sep\n",
      "    if isinstance(path, bytes):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3755788/222058142.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;31m# Best practice is to have your script execute via a main function call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3755788/222058142.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nGenerating data: {n_samples} samples, {n_features} features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_informative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_redundant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mest_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 ):\n\u001b[0;32m--> 218\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/datasets/_samples_generator.py\u001b[0m in \u001b[0;36mmake_classification\u001b[0;34m(n_samples, n_features, n_informative, n_redundant, n_repeated, n_classes, n_clusters_per_class, weights, flip_y, class_sep, hypercube, shift, scale, shuffle, random_state, return_X_y)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_random\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mn_random\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandard_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2076\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2080\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import make_classification\n",
    "import threading\n",
    "import os\n",
    "\n",
    "# --- Plotting Libraries ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Profiling and Estimator Libraries ---\n",
    "from memory_profiler import memory_usage\n",
    "try:\n",
    "    from pynvml import *\n",
    "    pynvml_available = True\n",
    "except ImportError:\n",
    "    pynvml_available = False\n",
    "\n",
    "from skrebate import ReliefF, SURF, SURFstar, MultiSURF as SkrebateMultiSURF, MultiSURFstar\n",
    "# Assuming your local implementations are in a 'src' directory\n",
    "from src.fast_select.ReliefF import ReliefF as FastReliefF\n",
    "from src.fast_select.SURF import SURF as FastSURF\n",
    "from src.fast_select.MultiSURF import MultiSURF as FastMultiSURF\n",
    "\n",
    "try:\n",
    "    from numba import cuda\n",
    "    GPU_AVAILABLE = cuda.is_available()\n",
    "    if pynvml_available and GPU_AVAILABLE:\n",
    "        nvmlInit()\n",
    "except (ImportError, NVMLError):\n",
    "    GPU_AVAILABLE = False\n",
    "\n",
    "# --- Benchmark Configuration ---\n",
    "P_DOMINANT_SCENARIOS = { \"n_samples\": 100, \"n_features_range\": [100000, 200000, 300000, 400000, 500000] }\n",
    "N_DOMINANT_SCENARIOS = { \"n_features\": 100, \"n_samples_range\": [10000, 20000, 30000, 40000, 50000] }\n",
    "N_FEATURES_TO_SELECT = 10\n",
    "N_REPEATS = 1 # Increased repeats for more stable averages in plots\n",
    "\n",
    "# --- Estimators to Test ---\n",
    "estimators = {\n",
    "    #\"skrebate.ReliefF\": ReliefF(n_features_to_select=N_FEATURES_TO_SELECT, n_jobs=-1),\n",
    "    #\"skrebate.MultiSURF\": SkrebateMultiSURF(n_features_to_select=N_FEATURES_TO_SELECT, n_jobs=-1),\n",
    "    \"fast_relief.ReliefF (CPU)\": FastReliefF(n_features_to_select=N_FEATURES_TO_SELECT, backend='cpu', verbose=True),\n",
    "    \"fast_relief.MultiSURF (CPU)\": FastMultiSURF(n_features_to_select=N_FEATURES_TO_SELECT, backend='cpu'),\n",
    "}\n",
    "if GPU_AVAILABLE:\n",
    "    print(\"NVIDIA GPU detected. Including GPU benchmarks.\")\n",
    "    estimators.update({\n",
    "        \"fast_relief.ReliefF (GPU)\": FastReliefF(n_features_to_select=N_FEATURES_TO_SELECT, backend='gpu'),\n",
    "        \"fast_relief.MultiSURF (GPU)\": FastMultiSURF(n_features_to_select=N_FEATURES_TO_SELECT, backend='gpu'),\n",
    "    })\n",
    "else:\n",
    "    print(\"No NVIDIA GPU detected. Skipping GPU benchmarks.\")\n",
    "\n",
    "\n",
    "# --- CORE BENCHMARKING FUNCTIONS (with memory profiling) ---\n",
    "def run_single_benchmark(estimator, X, y, is_gpu=False):\n",
    "    mem_increase_mb = -1.0\n",
    "    def fit_estimator():\n",
    "        estimator.fit(X, y)\n",
    "\n",
    "    if is_gpu and GPU_AVAILABLE and pynvml_available:\n",
    "        handle = nvmlDeviceGetHandleByIndex(0)\n",
    "        class MemTracker(threading.Thread):\n",
    "            def __init__(self):\n",
    "                threading.Thread.__init__(self)\n",
    "                self.peak_mem = 0\n",
    "                self.running = True\n",
    "            def run(self):\n",
    "                initial_mem = nvmlDeviceGetMemoryInfo(handle).used\n",
    "                while self.running:\n",
    "                    self.peak_mem = max(self.peak_mem, nvmlDeviceGetMemoryInfo(handle).used - initial_mem)\n",
    "                    time.sleep(0.01)\n",
    "            def stop(self):\n",
    "                self.running = False\n",
    "        tracker = MemTracker()\n",
    "        tracker.start()\n",
    "        start_time = time.perf_counter()\n",
    "        try:\n",
    "            fit_estimator()\n",
    "        finally:\n",
    "            tracker.stop()\n",
    "            tracker.join()\n",
    "        end_time = time.perf_counter()\n",
    "        mem_increase_mb = tracker.peak_mem / (1024**2)\n",
    "    else:\n",
    "        start_time = time.perf_counter()\n",
    "        mem_profile, _ = memory_usage((fit_estimator,), retval=True, interval=0.1)\n",
    "        end_time = time.perf_counter()\n",
    "        mem_increase_mb = max(mem_profile) - mem_profile[0]\n",
    "        \n",
    "    runtime = end_time - start_time\n",
    "    return runtime, mem_increase_mb\n",
    "\n",
    "def warmup_jit_compilers(estimators_dict):\n",
    "    print(\"\\n--- Warming up JIT compilers ---\")\n",
    "    X_warmup, y_warmup = make_classification(n_samples=10, n_features=10, random_state=42)\n",
    "    for name, estimator in estimators_dict.items():\n",
    "        if \"fast_relief\" in name:\n",
    "            print(f\"  Warming up {name}...\")\n",
    "            try:\n",
    "                clone(estimator).fit(X_warmup, y_warmup)\n",
    "            except Exception as e:\n",
    "                warnings.warn(f\"  > Warm-up FAILED for {name}. Reason: {e}\")\n",
    "    print(\"--- Warm-up complete ---\")\n",
    "\n",
    "\n",
    "def plot_scenario(df, scenario_name, x_axis, y_axis, title, filename):\n",
    "    \"\"\"\n",
    "    Generates and saves a line plot for a given benchmark scenario.\n",
    "    Handles potential pandas/matplotlib version conflicts automatically.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    scenario_df = df[df['scenario'] == scenario_name]\n",
    "\n",
    "    # Use seaborn for a clean, publication-quality line plot\n",
    "    # It automatically groups by 'algorithm' and calculates mean/confidence intervals\n",
    "    sns.lineplot(\n",
    "        data=scenario_df,\n",
    "        x=x_axis,\n",
    "        y=y_axis,\n",
    "        hue='algorithm',\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        errorbar=('ci', 95) # Show 95% confidence interval\n",
    "    )\n",
    "\n",
    "    # Adding plot labels and title\n",
    "    plt.title(title, fontsize=18, fontweight='bold')\n",
    "    plt.xlabel(x_axis.replace('_', ' ').title(), fontsize=14)\n",
    "    plt.ylabel(y_axis.replace('_', ' ').title(), fontsize=14)\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.legend(title='Algorithm', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make space for legend\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Plot saved to '{filename}'\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- MAIN EXECUTION BLOCK ---\n",
    "def main():\n",
    "    \"\"\"Main function to run all benchmark scenarios and generate plots.\"\"\"\n",
    "    results = []\n",
    "    output_dir = \"benchmark_plots\"\n",
    "    os.makedirs(output_dir, exist_ok=True) # Create directory for plots\n",
    "\n",
    "    warmup_jit_compilers(estimators)\n",
    "\n",
    "    # --- Run Benchmark Scenarios ---\n",
    "    scenarios = {\n",
    "        \"p >> n\": (P_DOMINANT_SCENARIOS, \"n_features\"),\n",
    "        \"n >> p\": (N_DOMINANT_SCENARIOS, \"n_samples\")\n",
    "    }\n",
    "\n",
    "    for name, (params, independent_var) in scenarios.items():\n",
    "        print(f\"\\n--- Running Scenario: {name} ---\")\n",
    "        if name == \"p >> n\":\n",
    "            param_range = params[\"n_features_range\"]\n",
    "            n_samples = params[\"n_samples\"]\n",
    "            for n_features in param_range:\n",
    "                print(f\"\\nGenerating data: {n_samples} samples, {n_features} features\")\n",
    "                X, y = make_classification(n_samples=n_samples, n_features=n_features, n_informative=20, n_redundant=100, random_state=42)\n",
    "                for est_name, estimator in estimators.items():\n",
    "                    for i in range(N_REPEATS):\n",
    "                        print(f\"  Benchmarking {est_name} (Run {i+1}/{N_REPEATS})...\")\n",
    "                        try:\n",
    "                            is_gpu = \"(GPU)\" in est_name\n",
    "                            runtime, memory_mb = run_single_benchmark(clone(estimator), X, y, is_gpu)\n",
    "                            results.append({\"scenario\": name, \"algorithm\": est_name, \"n_samples\": n_samples, \"n_features\": n_features, \"runtime\": runtime, \"memory_increase_mb\": memory_mb})\n",
    "                        except Exception as e:\n",
    "                            warnings.warn(f\"  > FAILED: {est_name}. Reason: {e}\")\n",
    "        else: # n >> p\n",
    "            param_range = params[\"n_samples_range\"]\n",
    "            n_features = params[\"n_features\"]\n",
    "            for n_samples in param_range:\n",
    "                print(f\"\\nGenerating data: {n_samples} samples, {n_features} features\")\n",
    "                X, y = make_classification(n_samples=n_samples, n_features=n_features, n_informative=20, n_redundant=50, random_state=42)\n",
    "                for est_name, estimator in estimators.items():\n",
    "                    for i in range(N_REPEATS):\n",
    "                        print(f\"  Benchmarking {est_name} (Run {i+1}/{N_REPEATS})...\")\n",
    "                        try:\n",
    "                            is_gpu = \"(GPU)\" in est_name\n",
    "                            runtime, memory_mb = run_single_benchmark(clone(estimator), X, y, is_gpu)\n",
    "                            results.append({\"scenario\": name, \"algorithm\": est_name, \"n_samples\": n_samples, \"n_features\": n_features, \"runtime\": runtime, \"memory_increase_mb\": memory_mb})\n",
    "                        except Exception as e:\n",
    "                            warnings.warn(f\"  > FAILED: {est_name}. Reason: {e}\")\n",
    "    \n",
    "    # --- Save results to CSV ---\n",
    "    df = pd.DataFrame(results)\n",
    "    output_file = \"benchmark_results_with_memory.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nBenchmarking complete. Results saved to '{output_file}'\")\n",
    "\n",
    "    # --- Generate and Save Plots ---\n",
    "    print(\"\\n--- Generating Plots ---\")\n",
    "    \n",
    "    # Plot 1: Runtime for p >> n\n",
    "    plot_scenario(df, 'p >> n', 'n_features', 'runtime', \n",
    "                  'Runtime Performance (Many Features, p >> n)', \n",
    "                  os.path.join(output_dir, 'p_dominant_runtime.png'))\n",
    "\n",
    "    # Plot 2: Memory for p >> n\n",
    "    plot_scenario(df, 'p >> n', 'n_features', 'memory_increase_mb', \n",
    "                  'Memory Usage (Many Features, p >> n)', \n",
    "                  os.path.join(output_dir, 'p_dominant_memory.png'))\n",
    "\n",
    "    # Plot 3: Runtime for n >> p\n",
    "    plot_scenario(df, 'n >> p', 'n_samples', 'runtime', \n",
    "                  'Runtime Performance (Many Samples, n >> p)', \n",
    "                  os.path.join(output_dir, 'n_dominant_runtime.png'))\n",
    "\n",
    "    # Plot 4: Memory for n >> p\n",
    "    plot_scenario(df, 'n >> p', 'n_samples', 'memory_increase_mb', \n",
    "                  'Memory Usage (Many Samples, n >> p)', \n",
    "                  os.path.join(output_dir, 'n_dominant_memory.png'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Best practice is to have your script execute via a main function call\n",
    "    main()\n",
    "    \n",
    "    # Clean up NVML\n",
    "    if GPU_AVAILABLE and pynvml_available:\n",
    "        try:\n",
    "            nvmlShutdown()\n",
    "        except NVMLError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05174a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main adf3094] working on ReliefF and MultiSURF\n",
      " 4 files changed, 68 insertions(+), 94 deletions(-)\n",
      " delete mode 100644 src/fast_select/temp.py\n",
      "Enumerating objects: 13, done.\n",
      "Counting objects: 100% (13/13), done.\n",
      "Delta compression using up to 20 threads\n",
      "Compressing objects: 100% (7/7), done.\n",
      "Writing objects: 100% (7/7), 1.87 KiB | 958.00 KiB/s, done.\n",
      "Total 7 (delta 5), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (5/5), completed with 5 local objects.\u001b[K\n",
      "To https://github.com/GavinLynch04/FastSelect.git\n",
      "   d6d1e9b..adf3094  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git commit -a -m \"working on ReliefF and MultiSURF\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d2c79e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: pytest: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9eaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
