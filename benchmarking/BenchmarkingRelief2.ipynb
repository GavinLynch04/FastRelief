{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5fcbaf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GPU detected. Including GPU benchmarks.\n",
      "\n",
      "--- Warming up JIT compilers ---\n",
      "  Warming up fast_select.ReliefF (CPU)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galynch/snap/snapd-desktop-integration/253/Desktop/FastSelect/src/fast_select/ReliefF.py:360: UserWarning: n_neighbors (10) is greater than or equal to the smallest class size (10).\n",
      "  warnings.warn(\n",
      "/home/galynch/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Warming up fast_select.SURF (CPU)...\n",
      "  Warming up fast_select.MultiSURF (CPU)...\n",
      "  Warming up fast_select.ReliefF (GPU)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galynch/snap/snapd-desktop-integration/253/Desktop/FastSelect/src/fast_select/ReliefF.py:360: UserWarning: n_neighbors (10) is greater than or equal to the smallest class size (10).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Warming up fast_select.SURF (GPU)...\n",
      "  Warming up fast_select.MultiSURF (GPU)...\n",
      "--- Warm-up complete ---\n",
      "\n",
      "--- Running Scenario: p >> n (Features Dominant) ---\n",
      "\n",
      "Generating data: 500 samples, 100 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 500 samples, 200 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 500 samples, 300 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 500 samples, 400 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 500 samples, 500 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "--- Running Scenario: n >> p (Samples Dominant) ---\n",
      "\n",
      "Generating data: 500 samples, 100 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 1000 samples, 100 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 1500 samples, 100 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 2000 samples, 100 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 2500 samples, 100 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Benchmarking complete. Results saved to 'benchmark_results_with_memory.csv'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import psutil\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import make_classification\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# --- Your other imports ---\n",
    "from skrebate import ReliefF, SURF, SURFstar, MultiSURF as SkrebateMultiSURF, MultiSURFstar\n",
    "from src.fast_select.ReliefF import ReliefF as FastReliefF\n",
    "from src.fast_select.SURF import SURF as FastSURF\n",
    "from src.fast_select.MultiSURF import MultiSURF as FastMultiSURF\n",
    "\n",
    "# --- GPU Detection ---\n",
    "try:\n",
    "    from numba import cuda\n",
    "    GPU_AVAILABLE = cuda.is_available()\n",
    "except (ImportError, cuda.cudadrv.error.CudaSupportError):\n",
    "    GPU_AVAILABLE = False\n",
    "\n",
    "# --- Benchmark Configuration ---\n",
    "P_DOMINANT_SCENARIOS = {\n",
    "    \"name\": \"p >> n (Features Dominant)\",\n",
    "    \"fixed_param\": \"n_samples\", \"fixed_value\": 500,\n",
    "    \"varied_param\": \"n_features\", \"varied_range\": [100, 200, 300, 400, 500]\n",
    "}\n",
    "N_DOMINANT_SCENARIOS = {\n",
    "    \"name\": \"n >> p (Samples Dominant)\",\n",
    "    \"fixed_param\": \"n_features\", \"fixed_value\": 100,\n",
    "    \"varied_param\": \"n_samples\", \"varied_range\": [500, 1000, 1500, 2000, 2500]\n",
    "}\n",
    "N_FEATURES_TO_SELECT = 10\n",
    "N_REPEATS = 3 # Increase repeats for more stable results\n",
    "\n",
    "# --- Estimators to Test ---\n",
    "estimators = {\n",
    "    # skrebate estimators\n",
    "    \"skrebate.ReliefF\": ReliefF(n_features_to_select=N_FEATURES_TO_SELECT, n_neighbors=10, n_jobs=-1),\n",
    "    \"skrebate.SURF\": SURF(n_features_to_select=N_FEATURES_TO_SELECT, n_jobs=-1),\n",
    "    \"skrebate.MultiSURF\": SkrebateMultiSURF(n_features_to_select=N_FEATURES_TO_SELECT, n_jobs=-1),\n",
    "    # fast-select CPU estimators\n",
    "    \"fast_select.ReliefF (CPU)\": FastReliefF(n_features_to_select=N_FEATURES_TO_SELECT, n_neighbors=10, backend='cpu', n_jobs=-1),\n",
    "    \"fast_select.SURF (CPU)\": FastSURF(n_features_to_select=N_FEATURES_TO_SELECT, n_jobs=-1),\n",
    "    \"fast_select.MultiSURF (CPU)\": FastMultiSURF(n_features_to_select=N_FEATURES_TO_SELECT, backend='cpu', n_jobs=-1),\n",
    "}\n",
    "if GPU_AVAILABLE:\n",
    "    print(\"NVIDIA GPU detected. Including GPU benchmarks.\")\n",
    "    estimators.update({\n",
    "        \"fast_select.ReliefF (GPU)\": FastReliefF(n_features_to_select=N_FEATURES_TO_SELECT, n_neighbors=10, backend='gpu'),\n",
    "        \"fast_select.SURF (GPU)\": FastSURF(n_features_to_select=N_FEATURES_TO_SELECT, backend='gpu'),\n",
    "        \"fast_select.MultiSURF (GPU)\": FastMultiSURF(n_features_to_select=N_FEATURES_TO_SELECT, backend='gpu'),\n",
    "    })\n",
    "else:\n",
    "    print(\"No NVIDIA GPU detected. Skipping GPU benchmarks.\")\n",
    "\n",
    "# --- CORRECTED BENCHMARK FUNCTION ---\n",
    "def run_single_benchmark(estimator, X, y):\n",
    "    \"\"\"\n",
    "    Measures runtime and peak memory usage of a single estimator fit.\n",
    "    This version performs only ONE execution and correctly measures GPU memory.\n",
    "    \"\"\"\n",
    "    is_gpu_estimator = hasattr(estimator, 'backend') and estimator.backend == 'gpu'\n",
    "    \n",
    "    # Use a lambda to wrap the fit call\n",
    "    fit_func = lambda: estimator.fit(X, y)\n",
    "\n",
    "    # --- Memory Measurement ---\n",
    "    peak_mem_mb = 0\n",
    "    if is_gpu_estimator:\n",
    "        # For GPU, we measure VRAM usage directly.\n",
    "        # This requires the fit function to be run inside the context.\n",
    "        ctx = cuda.current_context()\n",
    "        start_mem = ctx.get_memory_info().free\n",
    "        fit_func() # Run the function\n",
    "        end_mem = ctx.get_memory_info().free\n",
    "        # Peak memory is the reduction in free memory.\n",
    "        peak_mem_mb = (start_mem - end_mem) / (1024**2)\n",
    "    else:\n",
    "        # For CPU, memory_profiler works perfectly.\n",
    "        mem_samples = memory_usage(fit_func, interval=0.1)\n",
    "        peak_mem_mb = max(mem_samples)\n",
    "\n",
    "    # --- Runtime Measurement ---\n",
    "    # Since the function has already been run once for memory profiling,\n",
    "    # we time a second run to get a pure execution time without JIT overhead.\n",
    "    # This is now a consistent measurement.\n",
    "    start_time = time.perf_counter()\n",
    "    fit_func()\n",
    "    end_time = time.perf_counter()\n",
    "    runtime = end_time - start_time\n",
    "    \n",
    "    return runtime, peak_mem_mb\n",
    "\n",
    "def warmup_jit_compilers(estimators_dict):\n",
    "    \"\"\"Performs a 'warm-up' run on a small dataset to compile JIT functions.\"\"\"\n",
    "    print(\"\\n--- Warming up JIT compilers ---\")\n",
    "    X_warmup, y_warmup = make_classification(n_samples=20, n_features=20, random_state=42)\n",
    "    for name, estimator in estimators_dict.items():\n",
    "        # More robust check for our custom estimators\n",
    "        if \"fast_select\" in name:\n",
    "            print(f\"  Warming up {name}...\")\n",
    "            try:\n",
    "                # Use a fresh clone for warmup\n",
    "                clone(estimator).fit(X_warmup, y_warmup)\n",
    "            except Exception as e:\n",
    "                warnings.warn(f\"  > Warm-up FAILED for {name}. Reason: {type(e).__name__}: {e}\")\n",
    "    print(\"--- Warm-up complete ---\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run all benchmark scenarios.\"\"\"\n",
    "    results = []\n",
    "    warmup_jit_compilers(estimators)\n",
    "\n",
    "    scenarios = [P_DOMINANT_SCENARIOS, N_DOMINANT_SCENARIOS]\n",
    "    \n",
    "    for scenario_params in scenarios:\n",
    "        scenario_name = scenario_params[\"name\"]\n",
    "        print(f\"\\n--- Running Scenario: {scenario_name} ---\")\n",
    "        \n",
    "        fixed_param = scenario_params[\"fixed_param\"]\n",
    "        varied_param = scenario_params[\"varied_param\"]\n",
    "        \n",
    "        for varied_value in scenario_params[\"varied_range\"]:\n",
    "            # Set up dataset dimensions for this run\n",
    "            if fixed_param == \"n_samples\":\n",
    "                n_samples = scenario_params[\"fixed_value\"]\n",
    "                n_features = varied_value\n",
    "            else:\n",
    "                n_samples = varied_value\n",
    "                n_features = scenario_params[\"fixed_value\"]\n",
    "                \n",
    "            print(f\"\\nGenerating data: {n_samples} samples, {n_features} features\")\n",
    "            X, y = make_classification(n_samples=n_samples, n_features=n_features, n_informative=20, n_redundant=50, random_state=42)\n",
    "\n",
    "            for name, base_estimator in estimators.items():\n",
    "                for i in range(N_REPEATS):\n",
    "                    print(f\"  Benchmarking {name} (Run {i+1}/{N_REPEATS})...\")\n",
    "                    try:\n",
    "                        estimator = clone(base_estimator)\n",
    "                        runtime, peak_mem = run_single_benchmark(estimator, X, y)\n",
    "                        results.append({\n",
    "                            \"scenario\": scenario_name, \"algorithm\": name,\n",
    "                            \"n_samples\": n_samples, \"n_features\": n_features,\n",
    "                            \"runtime_sec\": runtime, \"peak_memory_mb\": peak_mem\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        warnings.warn(f\"  > FAILED: {name} on {n_samples}x{n_features}. Reason: {type(e).__name__}: {e}\", UserWarning)\n",
    "\n",
    "    # --- Save results to CSV ---\n",
    "    df = pd.DataFrame(results)\n",
    "    output_file = \"benchmark_results_with_memory.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nBenchmarking complete. Results saved to '{output_file}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05174a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[development 58cfac2] documentation updates: added user guide\n",
      "Enumerating objects: 25, done.\n",
      "Counting objects: 100% (19/19), done.\n",
      "Delta compression using up to 20 threads\n",
      "Compressing objects: 100% (11/11), done.\n",
      "Writing objects: 100% (11/11), 5.33 KiB | 2.66 MiB/s, done.\n",
      "Total 11 (delta 7), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (7/7), completed with 6 local objects.\u001b[K\n",
      "To https://github.com/GavinLynch04/FastSelect.git\n",
      "   fe234e0..58cfac2  development -> development\n"
     ]
    }
   ],
   "source": [
    "!git commit -a -m \"documentation updates: added user guide\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2c79e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!git pull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae9eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add ../docs/source/user_guide.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7818c054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v12.22.9\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c3a7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33ms\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33ms\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33ms\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m [ 88%]\n",
      "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                                                [100%]\u001b[0m\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_________________________ test_fit_transform_cpu[MID] __________________________\u001b[0m\n",
      "\n",
      "discrete_classification_data = (array([[3, 0, 1, ..., 3, 1, 2],\n",
      "       [0, 1, 3, ..., 0, 2, 3],\n",
      "       [3, 1, 0, ..., 3, 1, 0],\n",
      "       ...,\n",
      "       [0...,\n",
      "       2, 0, 1, 3, 2, 1, 0, 2, 3, 0, 0, 2, 1, 2, 3, 3, 1, 3, 1, 2, 0, 1,\n",
      "       2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 0]))\n",
      "method = 'MID'\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[33m'\u001b[39;49;00m\u001b[33mMID\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mMIQ\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_fit_transform_cpu\u001b[39;49;00m(discrete_classification_data, method):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Test the full fit and transform cycle on the CPU backend for both methods.\u001b[39;49;00m\n",
      "    \u001b[33m    This covers the CPU host caller and JIT kernels.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        X, y = discrete_classification_data\u001b[90m\u001b[39;49;00m\n",
      "        n_samples, n_features = X.shape\u001b[90m\u001b[39;49;00m\n",
      "        n_select = \u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        model = mRMR(n_features_to_select=n_select, method=method, backend=\u001b[33m'\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Test fit()\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       model.fit(X, y)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_mrmr.py\u001b[0m:66: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = mRMR(n_features_to_select=5)\n",
      "X = array([[3, 0, 1, ..., 3, 1, 2],\n",
      "       [0, 1, 3, ..., 0, 2, 3],\n",
      "       [3, 1, 0, ..., 3, 1, 0],\n",
      "       ...,\n",
      "       [0, 0, 2, ..., 1, 3, 2],\n",
      "       [0, 0, 2, ..., 1, 3, 1],\n",
      "       [2, 3, 1, ..., 3, 1, 1]])\n",
      "y = array([0, 1, 0, 3, 0, 0, 0, 3, 0, 3, 3, 3, 2, 3, 3, 1, 0, 1, 1, 0, 0, 2,\n",
      "       3, 3, 1, 2, 1, 1, 1, 3, 2, 2, 3, 0, 3,...2,\n",
      "       2, 0, 1, 3, 2, 1, 0, 2, 3, 0, 0, 2, 1, 2, 3, 3, 1, 3, 1, 2, 0, 1,\n",
      "       2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 0])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mfit\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, X: np.ndarray, y: np.ndarray):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Fits the mRMR model to select the best features.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    X : array-like of shape (n_samples, n_features)\u001b[39;49;00m\n",
      "    \u001b[33m        The training input samples. Assumed to be discrete.\u001b[39;49;00m\n",
      "    \u001b[33m    y : array-like of shape (n_samples,)\u001b[39;49;00m\n",
      "    \u001b[33m        The target values. Assumed to be discrete.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns\u001b[39;49;00m\n",
      "    \u001b[33m    -------\u001b[39;49;00m\n",
      "    \u001b[33m    self : object\u001b[39;49;00m\n",
      "    \u001b[33m        Returns the instance itself.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        X, y = validate_data(\u001b[96mself\u001b[39;49;00m, X, y, dtype=\u001b[94mNone\u001b[39;49;00m, y_numeric=\u001b[94mTrue\u001b[39;49;00m, ensure_2d=\u001b[94mTrue\u001b[39;49;00m,)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m.n_features_in_ = X.shape[\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m (\u001b[94m0\u001b[39;49;00m < \u001b[96mself\u001b[39;49;00m.n_features_to_select <= \u001b[96mself\u001b[39;49;00m.n_features_in_):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mn_features_to_select must be a positive integer less \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mthan or equal to the number of features.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      "        unique_vals = np.unique(np.concatenate([np.unique(X), np.unique(y)]))\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m.unique_vals_ = unique_vals\u001b[90m\u001b[39;49;00m\n",
      "        n_states = \u001b[96mlen\u001b[39;49;00m(unique_vals)\u001b[90m\u001b[39;49;00m\n",
      "        X_encoded, y_encoded = _encode_data_numba(X, y, unique_vals)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       relevance, redundancy = mi.calculate_mi_matrices(\u001b[90m\u001b[39;49;00m\n",
      "            X_encoded, y_encoded, n_states, \u001b[96mself\u001b[39;49;00m.backend\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AttributeError: module 'fast_select.mutual_information' has no attribute 'calculate_mi_matrices'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31msrc/fast_select/mRMR.py\u001b[0m:98: AttributeError\n",
      "\u001b[31m\u001b[1m_________________________ test_fit_transform_cpu[MIQ] __________________________\u001b[0m\n",
      "\n",
      "discrete_classification_data = (array([[3, 0, 1, ..., 3, 1, 2],\n",
      "       [0, 1, 3, ..., 0, 2, 3],\n",
      "       [3, 1, 0, ..., 3, 1, 0],\n",
      "       ...,\n",
      "       [0...,\n",
      "       2, 0, 1, 3, 2, 1, 0, 2, 3, 0, 0, 2, 1, 2, 3, 3, 1, 3, 1, 2, 0, 1,\n",
      "       2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 0]))\n",
      "method = 'MIQ'\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[33m'\u001b[39;49;00m\u001b[33mMID\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mMIQ\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_fit_transform_cpu\u001b[39;49;00m(discrete_classification_data, method):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Test the full fit and transform cycle on the CPU backend for both methods.\u001b[39;49;00m\n",
      "    \u001b[33m    This covers the CPU host caller and JIT kernels.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        X, y = discrete_classification_data\u001b[90m\u001b[39;49;00m\n",
      "        n_samples, n_features = X.shape\u001b[90m\u001b[39;49;00m\n",
      "        n_select = \u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        model = mRMR(n_features_to_select=n_select, method=method, backend=\u001b[33m'\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Test fit()\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       model.fit(X, y)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_mrmr.py\u001b[0m:66: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = mRMR(method='MIQ', n_features_to_select=5)\n",
      "X = array([[3, 0, 1, ..., 3, 1, 2],\n",
      "       [0, 1, 3, ..., 0, 2, 3],\n",
      "       [3, 1, 0, ..., 3, 1, 0],\n",
      "       ...,\n",
      "       [0, 0, 2, ..., 1, 3, 2],\n",
      "       [0, 0, 2, ..., 1, 3, 1],\n",
      "       [2, 3, 1, ..., 3, 1, 1]])\n",
      "y = array([0, 1, 0, 3, 0, 0, 0, 3, 0, 3, 3, 3, 2, 3, 3, 1, 0, 1, 1, 0, 0, 2,\n",
      "       3, 3, 1, 2, 1, 1, 1, 3, 2, 2, 3, 0, 3,...2,\n",
      "       2, 0, 1, 3, 2, 1, 0, 2, 3, 0, 0, 2, 1, 2, 3, 3, 1, 3, 1, 2, 0, 1,\n",
      "       2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 0])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mfit\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, X: np.ndarray, y: np.ndarray):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Fits the mRMR model to select the best features.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    X : array-like of shape (n_samples, n_features)\u001b[39;49;00m\n",
      "    \u001b[33m        The training input samples. Assumed to be discrete.\u001b[39;49;00m\n",
      "    \u001b[33m    y : array-like of shape (n_samples,)\u001b[39;49;00m\n",
      "    \u001b[33m        The target values. Assumed to be discrete.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns\u001b[39;49;00m\n",
      "    \u001b[33m    -------\u001b[39;49;00m\n",
      "    \u001b[33m    self : object\u001b[39;49;00m\n",
      "    \u001b[33m        Returns the instance itself.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        X, y = validate_data(\u001b[96mself\u001b[39;49;00m, X, y, dtype=\u001b[94mNone\u001b[39;49;00m, y_numeric=\u001b[94mTrue\u001b[39;49;00m, ensure_2d=\u001b[94mTrue\u001b[39;49;00m,)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m.n_features_in_ = X.shape[\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m (\u001b[94m0\u001b[39;49;00m < \u001b[96mself\u001b[39;49;00m.n_features_to_select <= \u001b[96mself\u001b[39;49;00m.n_features_in_):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mn_features_to_select must be a positive integer less \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mthan or equal to the number of features.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      "        unique_vals = np.unique(np.concatenate([np.unique(X), np.unique(y)]))\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m.unique_vals_ = unique_vals\u001b[90m\u001b[39;49;00m\n",
      "        n_states = \u001b[96mlen\u001b[39;49;00m(unique_vals)\u001b[90m\u001b[39;49;00m\n",
      "        X_encoded, y_encoded = _encode_data_numba(X, y, unique_vals)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       relevance, redundancy = mi.calculate_mi_matrices(\u001b[90m\u001b[39;49;00m\n",
      "            X_encoded, y_encoded, n_states, \u001b[96mself\u001b[39;49;00m.backend\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AttributeError: module 'fast_select.mutual_information' has no attribute 'calculate_mi_matrices'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31msrc/fast_select/mRMR.py\u001b[0m:98: AttributeError\n",
      "\u001b[31m\u001b[1m_________________________ test_fit_transform_gpu[MID] __________________________\u001b[0m\n",
      "\n",
      "discrete_classification_data = (array([[3, 0, 1, ..., 3, 1, 2],\n",
      "       [0, 1, 3, ..., 0, 2, 3],\n",
      "       [3, 1, 0, ..., 3, 1, 0],\n",
      "       ...,\n",
      "       [0...,\n",
      "       2, 0, 1, 3, 2, 1, 0, 2, 3, 0, 0, 2, 1, 2, 3, 3, 1, 3, 1, 2, 0, 1,\n",
      "       2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 0]))\n",
      "method = 'MID'\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.skipif(\u001b[95mnot\u001b[39;49;00m cuda.is_available(), reason=\u001b[33m\"\u001b[39;49;00m\u001b[33mNVIDIA GPU with CUDA not available\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[33m'\u001b[39;49;00m\u001b[33mMID\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mMIQ\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_fit_transform_gpu\u001b[39;49;00m(discrete_classification_data, method):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Test the full fit and transform cycle on the GPU backend for both methods.\u001b[39;49;00m\n",
      "    \u001b[33m    This covers the GPU host caller and CUDA kernels. Skipped if no GPU.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        X, y = discrete_classification_data\u001b[90m\u001b[39;49;00m\n",
      "        n_samples, n_features = X.shape\u001b[90m\u001b[39;49;00m\n",
      "        n_select = \u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        model = mRMR(n_features_to_select=n_select, method=method, backend=\u001b[33m'\u001b[39;49;00m\u001b[33mgpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Test fit()\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       model.fit(X, y)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_mrmr.py\u001b[0m:97: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = mRMR(backend='gpu', n_features_to_select=5)\n",
      "X = array([[3, 0, 1, ..., 3, 1, 2],\n",
      "       [0, 1, 3, ..., 0, 2, 3],\n",
      "       [3, 1, 0, ..., 3, 1, 0],\n",
      "       ...,\n",
      "       [0, 0, 2, ..., 1, 3, 2],\n",
      "       [0, 0, 2, ..., 1, 3, 1],\n",
      "       [2, 3, 1, ..., 3, 1, 1]])\n",
      "y = array([0, 1, 0, 3, 0, 0, 0, 3, 0, 3, 3, 3, 2, 3, 3, 1, 0, 1, 1, 0, 0, 2,\n",
      "       3, 3, 1, 2, 1, 1, 1, 3, 2, 2, 3, 0, 3,...2,\n",
      "       2, 0, 1, 3, 2, 1, 0, 2, 3, 0, 0, 2, 1, 2, 3, 3, 1, 3, 1, 2, 0, 1,\n",
      "       2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 0])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mfit\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, X: np.ndarray, y: np.ndarray):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Fits the mRMR model to select the best features.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    X : array-like of shape (n_samples, n_features)\u001b[39;49;00m\n",
      "    \u001b[33m        The training input samples. Assumed to be discrete.\u001b[39;49;00m\n",
      "    \u001b[33m    y : array-like of shape (n_samples,)\u001b[39;49;00m\n",
      "    \u001b[33m        The target values. Assumed to be discrete.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns\u001b[39;49;00m\n",
      "    \u001b[33m    -------\u001b[39;49;00m\n",
      "    \u001b[33m    self : object\u001b[39;49;00m\n",
      "    \u001b[33m        Returns the instance itself.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        X, y = validate_data(\u001b[96mself\u001b[39;49;00m, X, y, dtype=\u001b[94mNone\u001b[39;49;00m, y_numeric=\u001b[94mTrue\u001b[39;49;00m, ensure_2d=\u001b[94mTrue\u001b[39;49;00m,)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m.n_features_in_ = X.shape[\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m (\u001b[94m0\u001b[39;49;00m < \u001b[96mself\u001b[39;49;00m.n_features_to_select <= \u001b[96mself\u001b[39;49;00m.n_features_in_):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mn_features_to_select must be a positive integer less \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mthan or equal to the number of features.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      "        unique_vals = np.unique(np.concatenate([np.unique(X), np.unique(y)]))\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m.unique_vals_ = unique_vals\u001b[90m\u001b[39;49;00m\n",
      "        n_states = \u001b[96mlen\u001b[39;49;00m(unique_vals)\u001b[90m\u001b[39;49;00m\n",
      "        X_encoded, y_encoded = _encode_data_numba(X, y, unique_vals)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       relevance, redundancy = mi.calculate_mi_matrices(\u001b[90m\u001b[39;49;00m\n",
      "            X_encoded, y_encoded, n_states, \u001b[96mself\u001b[39;49;00m.backend\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AttributeError: module 'fast_select.mutual_information' has no attribute 'calculate_mi_matrices'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31msrc/fast_select/mRMR.py\u001b[0m:98: AttributeError\n",
      "\u001b[31m\u001b[1m_________________________ test_fit_transform_gpu[MIQ] __________________________\u001b[0m\n",
      "\n",
      "discrete_classification_data = (array([[3, 0, 1, ..., 3, 1, 2],\n",
      "       [0, 1, 3, ..., 0, 2, 3],\n",
      "       [3, 1, 0, ..., 3, 1, 0],\n",
      "       ...,\n",
      "       [0...,\n",
      "       2, 0, 1, 3, 2, 1, 0, 2, 3, 0, 0, 2, 1, 2, 3, 3, 1, 3, 1, 2, 0, 1,\n",
      "       2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 0]))\n",
      "method = 'MIQ'\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.skipif(\u001b[95mnot\u001b[39;49;00m cuda.is_available(), reason=\u001b[33m\"\u001b[39;49;00m\u001b[33mNVIDIA GPU with CUDA not available\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[33m'\u001b[39;49;00m\u001b[33mMID\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mMIQ\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_fit_transform_gpu\u001b[39;49;00m(discrete_classification_data, method):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Test the full fit and transform cycle on the GPU backend for both methods.\u001b[39;49;00m\n",
      "    \u001b[33m    This covers the GPU host caller and CUDA kernels. Skipped if no GPU.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        X, y = discrete_classification_data\u001b[90m\u001b[39;49;00m\n",
      "        n_samples, n_features = X.shape\u001b[90m\u001b[39;49;00m\n",
      "        n_select = \u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        model = mRMR(n_features_to_select=n_select, method=method, backend=\u001b[33m'\u001b[39;49;00m\u001b[33mgpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Test fit()\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       model.fit(X, y)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_mrmr.py\u001b[0m:97: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = mRMR(backend='gpu', method='MIQ', n_features_to_select=5)\n",
      "X = array([[3, 0, 1, ..., 3, 1, 2],\n",
      "       [0, 1, 3, ..., 0, 2, 3],\n",
      "       [3, 1, 0, ..., 3, 1, 0],\n",
      "       ...,\n",
      "       [0, 0, 2, ..., 1, 3, 2],\n",
      "       [0, 0, 2, ..., 1, 3, 1],\n",
      "       [2, 3, 1, ..., 3, 1, 1]])\n",
      "y = array([0, 1, 0, 3, 0, 0, 0, 3, 0, 3, 3, 3, 2, 3, 3, 1, 0, 1, 1, 0, 0, 2,\n",
      "       3, 3, 1, 2, 1, 1, 1, 3, 2, 2, 3, 0, 3,...2,\n",
      "       2, 0, 1, 3, 2, 1, 0, 2, 3, 0, 0, 2, 1, 2, 3, 3, 1, 3, 1, 2, 0, 1,\n",
      "       2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 0])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mfit\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, X: np.ndarray, y: np.ndarray):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Fits the mRMR model to select the best features.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    X : array-like of shape (n_samples, n_features)\u001b[39;49;00m\n",
      "    \u001b[33m        The training input samples. Assumed to be discrete.\u001b[39;49;00m\n",
      "    \u001b[33m    y : array-like of shape (n_samples,)\u001b[39;49;00m\n",
      "    \u001b[33m        The target values. Assumed to be discrete.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns\u001b[39;49;00m\n",
      "    \u001b[33m    -------\u001b[39;49;00m\n",
      "    \u001b[33m    self : object\u001b[39;49;00m\n",
      "    \u001b[33m        Returns the instance itself.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        X, y = validate_data(\u001b[96mself\u001b[39;49;00m, X, y, dtype=\u001b[94mNone\u001b[39;49;00m, y_numeric=\u001b[94mTrue\u001b[39;49;00m, ensure_2d=\u001b[94mTrue\u001b[39;49;00m,)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m.n_features_in_ = X.shape[\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m (\u001b[94m0\u001b[39;49;00m < \u001b[96mself\u001b[39;49;00m.n_features_to_select <= \u001b[96mself\u001b[39;49;00m.n_features_in_):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mn_features_to_select must be a positive integer less \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mthan or equal to the number of features.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      "        unique_vals = np.unique(np.concatenate([np.unique(X), np.unique(y)]))\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m.unique_vals_ = unique_vals\u001b[90m\u001b[39;49;00m\n",
      "        n_states = \u001b[96mlen\u001b[39;49;00m(unique_vals)\u001b[90m\u001b[39;49;00m\n",
      "        X_encoded, y_encoded = _encode_data_numba(X, y, unique_vals)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       relevance, redundancy = mi.calculate_mi_matrices(\u001b[90m\u001b[39;49;00m\n",
      "            X_encoded, y_encoded, n_states, \u001b[96mself\u001b[39;49;00m.backend\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AttributeError: module 'fast_select.mutual_information' has no attribute 'calculate_mi_matrices'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31msrc/fast_select/mRMR.py\u001b[0m:98: AttributeError\n",
      "\u001b[31m\u001b[1m________________________ test_selects_correct_features _________________________\u001b[0m\n",
      "\n",
      "backend = 'cpu'\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mtest_selects_correct_features\u001b[39;49;00m(backend=\u001b[33m'\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Tests if mRMR selects the correct features on a synthetic dataset where\u001b[39;49;00m\n",
      "    \u001b[33m    the most relevant features are known and redundancy is controlled.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        n_samples = \u001b[94m200\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        n_features = \u001b[94m10\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Create a target variable\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        y = np.random.randint(\u001b[94m0\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, n_samples)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        X = np.random.randint(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, size=(n_samples, n_features))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        X[:, \u001b[94m0\u001b[39;49;00m] = y\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        X[:, \u001b[94m9\u001b[39;49;00m] = (y + np.random.randint(\u001b[94m0\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, n_samples)) % \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        X[:, \u001b[94m1\u001b[39;49;00m] = X[:, \u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        model = mRMR(n_features_to_select=\u001b[94m2\u001b[39;49;00m, method=\u001b[33m'\u001b[39;49;00m\u001b[33mMID\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, backend=backend)\u001b[90m\u001b[39;49;00m\n",
      ">       model.fit(X, y)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_mrmr.py\u001b[0m:127: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = mRMR(n_features_to_select=2)\n",
      "X = array([[0, 0, 0, ..., 0, 2, 1],\n",
      "       [1, 1, 2, ..., 2, 2, 0],\n",
      "       [1, 1, 1, ..., 1, 1, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 1, 2, 0],\n",
      "       [0, 0, 1, ..., 2, 1, 0],\n",
      "       [0, 0, 2, ..., 2, 2, 0]])\n",
      "y = array([0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,...0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "       0, 0])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mfit\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, X: np.ndarray, y: np.ndarray):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Fits the mRMR model to select the best features.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    X : array-like of shape (n_samples, n_features)\u001b[39;49;00m\n",
      "    \u001b[33m        The training input samples. Assumed to be discrete.\u001b[39;49;00m\n",
      "    \u001b[33m    y : array-like of shape (n_samples,)\u001b[39;49;00m\n",
      "    \u001b[33m        The target values. Assumed to be discrete.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns\u001b[39;49;00m\n",
      "    \u001b[33m    -------\u001b[39;49;00m\n",
      "    \u001b[33m    self : object\u001b[39;49;00m\n",
      "    \u001b[33m        Returns the instance itself.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        X, y = validate_data(\u001b[96mself\u001b[39;49;00m, X, y, dtype=\u001b[94mNone\u001b[39;49;00m, y_numeric=\u001b[94mTrue\u001b[39;49;00m, ensure_2d=\u001b[94mTrue\u001b[39;49;00m,)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m.n_features_in_ = X.shape[\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m (\u001b[94m0\u001b[39;49;00m < \u001b[96mself\u001b[39;49;00m.n_features_to_select <= \u001b[96mself\u001b[39;49;00m.n_features_in_):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mn_features_to_select must be a positive integer less \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mthan or equal to the number of features.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      "        unique_vals = np.unique(np.concatenate([np.unique(X), np.unique(y)]))\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m.unique_vals_ = unique_vals\u001b[90m\u001b[39;49;00m\n",
      "        n_states = \u001b[96mlen\u001b[39;49;00m(unique_vals)\u001b[90m\u001b[39;49;00m\n",
      "        X_encoded, y_encoded = _encode_data_numba(X, y, unique_vals)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       relevance, redundancy = mi.calculate_mi_matrices(\u001b[90m\u001b[39;49;00m\n",
      "            X_encoded, y_encoded, n_states, \u001b[96mself\u001b[39;49;00m.backend\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AttributeError: module 'fast_select.mutual_information' has no attribute 'calculate_mi_matrices'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31msrc/fast_select/mRMR.py\u001b[0m:98: AttributeError\n",
      "\u001b[31m\u001b[1m_____________________ test_sklearn_pipeline_compatibility ______________________\u001b[0m\n",
      "\n",
      "discrete_classification_data = (array([[3, 0, 1, ..., 3, 1, 2],\n",
      "       [0, 1, 3, ..., 0, 2, 3],\n",
      "       [3, 1, 0, ..., 3, 1, 0],\n",
      "       ...,\n",
      "       [0...,\n",
      "       2, 0, 1, 3, 2, 1, 0, 2, 3, 0, 0, 2, 1, 2, 3, 3, 1, 3, 1, 2, 0, 1,\n",
      "       2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 0]))\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mtest_sklearn_pipeline_compatibility\u001b[39;49;00m(discrete_classification_data):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Ensures that mRMR works as a step within a scikit-learn Pipeline.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        X, y = discrete_classification_data\u001b[90m\u001b[39;49;00m\n",
      "        n_select = \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        pipeline = Pipeline([\u001b[90m\u001b[39;49;00m\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mmrmr_selector\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, mRMR(n_features_to_select=n_select, backend=\u001b[33m'\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)),\u001b[90m\u001b[39;49;00m\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mclassifier\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, LogisticRegression(random_state=\u001b[94m42\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
      "        ])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# If this runs without errors, the pipeline compatibility is confirmed\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       pipeline.fit(X, y)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_mrmr.py\u001b[0m:148: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/home/galynch/.local/lib/python3.10/site-packages/sklearn/base.py\u001b[0m:1363: in wrapper\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m fit_method(estimator, *args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/home/galynch/.local/lib/python3.10/site-packages/sklearn/pipeline.py\u001b[0m:653: in fit\n",
      "    \u001b[0mXt = \u001b[96mself\u001b[39;49;00m._fit(X, y, routed_params, raw_params=params)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/home/galynch/.local/lib/python3.10/site-packages/sklearn/pipeline.py\u001b[0m:587: in _fit\n",
      "    \u001b[0mX, fitted_transformer = fit_transform_one_cached(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/home/galynch/.local/lib/python3.10/site-packages/joblib/memory.py\u001b[0m:353: in __call__\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/home/galynch/.local/lib/python3.10/site-packages/sklearn/pipeline.py\u001b[0m:1539: in _fit_transform_one\n",
      "    \u001b[0mres = transformer.fit_transform(X, y, **params.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mfit_transform\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, {}))\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/home/galynch/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py\u001b[0m:316: in wrapped\n",
      "    \u001b[0mdata_to_wrap = f(\u001b[96mself\u001b[39;49;00m, X, *args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31msrc/fast_select/mRMR.py\u001b[0m:149: in fit_transform\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.fit(X, y)\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = mRMR(n_features_to_select=3)\n",
      "X = array([[3, 0, 1, ..., 3, 1, 2],\n",
      "       [0, 1, 3, ..., 0, 2, 3],\n",
      "       [3, 1, 0, ..., 3, 1, 0],\n",
      "       ...,\n",
      "       [0, 0, 2, ..., 1, 3, 2],\n",
      "       [0, 0, 2, ..., 1, 3, 1],\n",
      "       [2, 3, 1, ..., 3, 1, 1]])\n",
      "y = array([0, 1, 0, 3, 0, 0, 0, 3, 0, 3, 3, 3, 2, 3, 3, 1, 0, 1, 1, 0, 0, 2,\n",
      "       3, 3, 1, 2, 1, 1, 1, 3, 2, 2, 3, 0, 3,...2,\n",
      "       2, 0, 1, 3, 2, 1, 0, 2, 3, 0, 0, 2, 1, 2, 3, 3, 1, 3, 1, 2, 0, 1,\n",
      "       2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 0])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mfit\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, X: np.ndarray, y: np.ndarray):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Fits the mRMR model to select the best features.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    X : array-like of shape (n_samples, n_features)\u001b[39;49;00m\n",
      "    \u001b[33m        The training input samples. Assumed to be discrete.\u001b[39;49;00m\n",
      "    \u001b[33m    y : array-like of shape (n_samples,)\u001b[39;49;00m\n",
      "    \u001b[33m        The target values. Assumed to be discrete.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns\u001b[39;49;00m\n",
      "    \u001b[33m    -------\u001b[39;49;00m\n",
      "    \u001b[33m    self : object\u001b[39;49;00m\n",
      "    \u001b[33m        Returns the instance itself.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        X, y = validate_data(\u001b[96mself\u001b[39;49;00m, X, y, dtype=\u001b[94mNone\u001b[39;49;00m, y_numeric=\u001b[94mTrue\u001b[39;49;00m, ensure_2d=\u001b[94mTrue\u001b[39;49;00m,)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m.n_features_in_ = X.shape[\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m (\u001b[94m0\u001b[39;49;00m < \u001b[96mself\u001b[39;49;00m.n_features_to_select <= \u001b[96mself\u001b[39;49;00m.n_features_in_):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mn_features_to_select must be a positive integer less \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mthan or equal to the number of features.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      "        unique_vals = np.unique(np.concatenate([np.unique(X), np.unique(y)]))\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m.unique_vals_ = unique_vals\u001b[90m\u001b[39;49;00m\n",
      "        n_states = \u001b[96mlen\u001b[39;49;00m(unique_vals)\u001b[90m\u001b[39;49;00m\n",
      "        X_encoded, y_encoded = _encode_data_numba(X, y, unique_vals)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       relevance, redundancy = mi.calculate_mi_matrices(\u001b[90m\u001b[39;49;00m\n",
      "            X_encoded, y_encoded, n_states, \u001b[96mself\u001b[39;49;00m.backend\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AttributeError: module 'fast_select.mutual_information' has no attribute 'calculate_mi_matrices'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31msrc/fast_select/mRMR.py\u001b[0m:98: AttributeError\n",
      "\u001b[31m\u001b[1m_________________________ test_input_validation_errors _________________________\u001b[0m\n",
      "\n",
      "discrete_classification_data = (array([[3, 0, 1, ..., 3, 1, 2],\n",
      "       [0, 1, 3, ..., 0, 2, 3],\n",
      "       [3, 1, 0, ..., 3, 1, 0],\n",
      "       ...,\n",
      "       [0...,\n",
      "       2, 0, 1, 3, 2, 1, 0, 2, 3, 0, 0, 2, 1, 2, 3, 3, 1, 3, 1, 2, 0, 1,\n",
      "       2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 0]))\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mtest_input_validation_errors\u001b[39;49;00m(discrete_classification_data):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test for errors raised on invalid input shapes or incorrect usage.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        X, y = discrete_classification_data\u001b[90m\u001b[39;49;00m\n",
      "        n_features = X.shape[\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        model = mRMR(n_features_to_select=\u001b[94m5\u001b[39;49;00m, backend=\u001b[33m'\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# 1. Calling transform before fit should raise NotFittedError\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mwith\u001b[39;49;00m pytest.raises(NotFittedError):\u001b[90m\u001b[39;49;00m\n",
      "            model.transform(X)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# 2. n_features_to_select > n_features should raise ValueError\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        bad_model = mRMR(n_features_to_select=n_features + \u001b[94m1\u001b[39;49;00m, backend=\u001b[33m'\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mwith\u001b[39;49;00m pytest.raises(\u001b[96mValueError\u001b[39;49;00m, match=\u001b[33m\"\u001b[39;49;00m\u001b[33mn_features_to_select must be a positive integer\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            bad_model.fit(X, y)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# 3. Calling transform with X of a different shape should raise ValueError\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       model.fit(X, y)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_mrmr.py\u001b[0m:170: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = mRMR(n_features_to_select=5)\n",
      "X = array([[3, 0, 1, ..., 3, 1, 2],\n",
      "       [0, 1, 3, ..., 0, 2, 3],\n",
      "       [3, 1, 0, ..., 3, 1, 0],\n",
      "       ...,\n",
      "       [0, 0, 2, ..., 1, 3, 2],\n",
      "       [0, 0, 2, ..., 1, 3, 1],\n",
      "       [2, 3, 1, ..., 3, 1, 1]])\n",
      "y = array([0, 1, 0, 3, 0, 0, 0, 3, 0, 3, 3, 3, 2, 3, 3, 1, 0, 1, 1, 0, 0, 2,\n",
      "       3, 3, 1, 2, 1, 1, 1, 3, 2, 2, 3, 0, 3,...2,\n",
      "       2, 0, 1, 3, 2, 1, 0, 2, 3, 0, 0, 2, 1, 2, 3, 3, 1, 3, 1, 2, 0, 1,\n",
      "       2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 0])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mfit\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, X: np.ndarray, y: np.ndarray):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Fits the mRMR model to select the best features.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    X : array-like of shape (n_samples, n_features)\u001b[39;49;00m\n",
      "    \u001b[33m        The training input samples. Assumed to be discrete.\u001b[39;49;00m\n",
      "    \u001b[33m    y : array-like of shape (n_samples,)\u001b[39;49;00m\n",
      "    \u001b[33m        The target values. Assumed to be discrete.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns\u001b[39;49;00m\n",
      "    \u001b[33m    -------\u001b[39;49;00m\n",
      "    \u001b[33m    self : object\u001b[39;49;00m\n",
      "    \u001b[33m        Returns the instance itself.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        X, y = validate_data(\u001b[96mself\u001b[39;49;00m, X, y, dtype=\u001b[94mNone\u001b[39;49;00m, y_numeric=\u001b[94mTrue\u001b[39;49;00m, ensure_2d=\u001b[94mTrue\u001b[39;49;00m,)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m.n_features_in_ = X.shape[\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m (\u001b[94m0\u001b[39;49;00m < \u001b[96mself\u001b[39;49;00m.n_features_to_select <= \u001b[96mself\u001b[39;49;00m.n_features_in_):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mn_features_to_select must be a positive integer less \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mthan or equal to the number of features.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      "        unique_vals = np.unique(np.concatenate([np.unique(X), np.unique(y)]))\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m.unique_vals_ = unique_vals\u001b[90m\u001b[39;49;00m\n",
      "        n_states = \u001b[96mlen\u001b[39;49;00m(unique_vals)\u001b[90m\u001b[39;49;00m\n",
      "        X_encoded, y_encoded = _encode_data_numba(X, y, unique_vals)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       relevance, redundancy = mi.calculate_mi_matrices(\u001b[90m\u001b[39;49;00m\n",
      "            X_encoded, y_encoded, n_states, \u001b[96mself\u001b[39;49;00m.backend\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AttributeError: module 'fast_select.mutual_information' has no attribute 'calculate_mi_matrices'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31msrc/fast_select/mRMR.py\u001b[0m:98: AttributeError\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "tests/test_chi2.py:141\n",
      "  /home/galynch/snap/snapd-desktop-integration/253/Desktop/FastSelect/tests/test_chi2.py:141: PytestUnknownMarkWarning: Unknown pytest.mark.slow - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.slow\n",
      "\n",
      "tests/test_chi2.py::test_correctness_against_sklearn[100-10-2]\n",
      "  /home/galynch/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "    warnings.warn(problem)\n",
      "\n",
      "tests/test_multisurf.py: 34 warnings\n",
      "tests/test_relieff.py: 40 warnings\n",
      "tests/test_surf.py: 35 warnings\n",
      "  /home/galynch/.local/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_multisurf.py::test_sklearn_api_compliance\n",
      "tests/test_relieff.py::test_sklearn_api_compliance\n",
      "tests/test_surf.py::test_sklearn_api_compliance\n",
      "  /home/galynch/.local/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 21 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_multisurf.py: 34 warnings\n",
      "  /home/galynch/.local/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:887: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_multisurf.py::test_sklearn_api_compliance\n",
      "tests/test_relieff.py::test_sklearn_api_compliance\n",
      "tests/test_surf.py::test_sklearn_api_compliance\n",
      "  /home/galynch/.local/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 20 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_multisurf.py::test_sklearn_api_compliance\n",
      "tests/test_relieff.py::test_sklearn_api_compliance\n",
      "tests/test_surf.py::test_sklearn_api_compliance\n",
      "  /home/galynch/.local/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 10 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_multisurf.py::test_sklearn_api_compliance\n",
      "tests/test_relieff.py::test_sklearn_api_compliance\n",
      "tests/test_surf.py::test_sklearn_api_compliance\n",
      "  /home/galynch/.local/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 40 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_multisurf.py::test_sklearn_api_compliance\n",
      "tests/test_relieff.py::test_sklearn_api_compliance\n",
      "tests/test_surf.py::test_sklearn_api_compliance\n",
      "  /home/galynch/.local/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 80 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_multisurf.py::test_sklearn_api_compliance\n",
      "tests/test_relieff.py::test_sklearn_api_compliance\n",
      "tests/test_surf.py::test_sklearn_api_compliance\n",
      "  /home/galynch/.local/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 100 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_relieff.py::test_feature_importance_ranking\n",
      "tests/test_surf.py::test_internal_consistency_cpu_gpu[False]\n",
      "  /home/galynch/.local/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 6 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_relieff.py::test_discrete_limit_parameter\n",
      "  /home/galynch/.local/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 22 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "    warn(NumbaPerformanceWarning(msg))\n",
      "\n",
      "tests/test_relieff.py::test_verbose_output\n",
      "tests/test_relieff.py::test_verbose_output\n",
      "  /home/galynch/snap/snapd-desktop-integration/253/Desktop/FastSelect/src/fast_select/ReliefF.py:360: UserWarning: n_neighbors (3) is greater than or equal to the smallest class size (3).\n",
      "    warnings.warn(\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "================================ tests coverage ================================\n",
      "_______________ coverage: platform linux, python 3.10.12-final-0 _______________\n",
      "\n",
      "Name                                    Stmts   Miss  Cover   Missing\n",
      "---------------------------------------------------------------------\n",
      "src/fast_select/CFS.py                     60     60     0%   1-249\n",
      "src/fast_select/Chi2.py                    21      0   100%\n",
      "src/fast_select/MDR.py                    172    172     0%   1-413\n",
      "src/fast_select/MultiSURF.py              104      4    96%   398, 400-405\n",
      "src/fast_select/ReliefF.py                 98      0   100%\n",
      "src/fast_select/SURF.py                    84      1    99%   342\n",
      "src/fast_select/TuRF.py                    50      0   100%\n",
      "src/fast_select/__init__.py                 7      0   100%\n",
      "src/fast_select/mRMR.py                   101     61    40%   64, 102-134, 139-145, 150, 162-170, 181-222\n",
      "src/fast_select/mutual_information.py       0      0   100%\n",
      "---------------------------------------------------------------------\n",
      "TOTAL                                     697    298    57%\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[33mSKIPPED\u001b[0m [1] tests/test_mrmr.py:46: This test is for when CUDA is NOT available\n",
      "\u001b[33mSKIPPED\u001b[0m [1] tests/test_multisurf.py:173: Skipping GPU error test: GPU is available.\n",
      "\u001b[33mSKIPPED\u001b[0m [1] tests/test_surf.py:127: Skipping GPU error test: GPU is available.\n",
      "\u001b[31mFAILED\u001b[0m tests/test_mrmr.py::\u001b[1mtest_fit_transform_cpu[MID]\u001b[0m - AttributeError: module 'fast_select.mutual_information' has no attribute 'c...\n",
      "\u001b[31mFAILED\u001b[0m tests/test_mrmr.py::\u001b[1mtest_fit_transform_cpu[MIQ]\u001b[0m - AttributeError: module 'fast_select.mutual_information' has no attribute 'c...\n",
      "\u001b[31mFAILED\u001b[0m tests/test_mrmr.py::\u001b[1mtest_fit_transform_gpu[MID]\u001b[0m - AttributeError: module 'fast_select.mutual_information' has no attribute 'c...\n",
      "\u001b[31mFAILED\u001b[0m tests/test_mrmr.py::\u001b[1mtest_fit_transform_gpu[MIQ]\u001b[0m - AttributeError: module 'fast_select.mutual_information' has no attribute 'c...\n",
      "\u001b[31mFAILED\u001b[0m tests/test_mrmr.py::\u001b[1mtest_selects_correct_features\u001b[0m - AttributeError: module 'fast_select.mutual_information' has no attribute 'c...\n",
      "\u001b[31mFAILED\u001b[0m tests/test_mrmr.py::\u001b[1mtest_sklearn_pipeline_compatibility\u001b[0m - AttributeError: module 'fast_select.mutual_information' has no attribute 'c...\n",
      "\u001b[31mFAILED\u001b[0m tests/test_mrmr.py::\u001b[1mtest_input_validation_errors\u001b[0m - AttributeError: module 'fast_select.mutual_information' has no attribute 'c...\n",
      "\u001b[31m\u001b[31m\u001b[1m7 failed\u001b[0m, \u001b[32m71 passed\u001b[0m, \u001b[33m3 skipped\u001b[0m, \u001b[33m168 warnings\u001b[0m\u001b[31m in 15.64s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01115427",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -type d -name \".pytest_cache\" -exec rm -r {} +\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ced03e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3958387/1494166838.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_large_robust_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSKMultiSURF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSURFSK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/skrebate/relieff.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    192\u001b[0m        \u001b[0;31m# Run remainder of algorithm (i.e. identification of 'neighbors' for each instance, and feature scoring).------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# Stores feature importance scores for ReliefF or respective Relief-based algorithm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# Delete the internal distance array because it is no longer needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/skrebate/multisurfstar.py\u001b[0m in \u001b[0;36m_run_algorithm\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mNN_far_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mNNlist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         scores = np.sum(Parallel(n_jobs=self.n_jobs)(delayed(\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mMultiSURFstar_compute_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_entries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmcmap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                                           NN_near, NN_far, self._headers, self._class_type, self._X, self._y, self._labels_std, self.data_type)\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/skrebate/scoring_utils.py\u001b[0m in \u001b[0;36mMultiSURFstar_compute_scores\u001b[0;34m(inst, attr, nan_entries, num_attributes, mcmap, NN_near, NN_far, headers, class_type, X, y, labels_std, data_type)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;31m# Note that we add this term because we used the far scoring above by setting 'near' to False.  This is in line with original MultiSURF* paper.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN_far\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             scores[feature_num] += compute_score(attr, mcmap, NN_far, feature_num, inst,\n\u001b[0m\u001b[1;32m    407\u001b[0m                                                  nan_entries, headers, class_type, X, y, labels_std, data_type, near=False)\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/skrebate/scoring_utils.py\u001b[0m in \u001b[0;36mcompute_score\u001b[0;34m(attr, mcmap, NN, feature, inst, nan_entries, headers, class_type, X, y, labels_std, data_type, near)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# HIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mcount_hit\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mftype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'continuous'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                         \u001b[0;31m#diff_hit -= abs(xinstfeature - xNNifeature) / mmdiff  #Hits differently add continuous value differences rather than subtract them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from skrebate import MultiSURFstar as SKMultiSURF\n",
    "from skrebate import SURFstar as SURFSK\n",
    "from skrebate import ReliefF as ReliefFSK\n",
    "import numpy as np\n",
    "def generate_large_robust_dataset(n_samples=1000, seed=29):\n",
    "    np.random.seed(seed)\n",
    "    # Create balanced binary classes\n",
    "    n0 = n_samples // 2\n",
    "    n1 = n_samples - n0\n",
    "    y = np.array([0] * n0 + [1] * n1, dtype=np.int32)\n",
    "\n",
    "    # Feature 0: Highly relevant continuous feature.\n",
    "    # Class 0 samples come from N(1, 1), class 1 samples come from N(10, 1).\n",
    "    f0_class0 = np.random.normal(loc=1.0, scale=1.0, size=n0)\n",
    "    f0_class1 = np.random.normal(loc=10.0, scale=1.0, size=n1)\n",
    "    f0 = np.concatenate([f0_class0, f0_class1])\n",
    "\n",
    "    # Feature 1: Irrelevant noise feature.\n",
    "    # Values drawn from a standard normal distribution regardless of class.\n",
    "    f1 = np.random.normal(loc=0.0, scale=1.0, size=n_samples)\n",
    "\n",
    "    # Feature 2: Relevant discrete feature.\n",
    "    # Class 0 predominantly gets value 10 but with a small chance for 20,\n",
    "    # and class 1 predominantly gets value 20 but with a small chance for 10.\n",
    "    f2_class0 = np.random.choice([10, 20], size=n0, p=[0.9, 0.1])\n",
    "    f2_class1 = np.random.choice([20, 10], size=n1, p=[0.9, 0.1])\n",
    "    f2 = np.concatenate([f2_class0, f2_class1])\n",
    "\n",
    "    # Feature 3: Irrelevant constant feature.\n",
    "    f3 = np.full((n_samples,), 3.0)\n",
    "\n",
    "    # Assemble features into one array.\n",
    "    X = np.column_stack([f0, f1, f2, f3]).astype(np.float32)\n",
    "\n",
    "    # Shuffle the dataset (so the classes are randomly interleaved)\n",
    "    idx = np.arange(n_samples)\n",
    "    np.random.shuffle(idx)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "    return X, y\n",
    "\n",
    "X,y = generate_large_robust_dataset()\n",
    "model = SKMultiSURF()\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)\n",
    "model = SURFSK()\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)\n",
    "model = ReliefFSK()\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b388ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fast_select import MultiSURF, ReliefF, SURF\n",
    "import numpy as np\n",
    "def generate_large_robust_dataset(n_samples=10000, seed=59):\n",
    "    np.random.seed(seed)\n",
    "    # Create balanced binary classes\n",
    "    n0 = n_samples // 2\n",
    "    n1 = n_samples - n0\n",
    "    y = np.array([0] * n0 + [1] * n1, dtype=np.int32)\n",
    "\n",
    "    # Feature 0: Highly relevant continuous feature.\n",
    "    # Class 0 samples come from N(1, 1), class 1 samples come from N(10, 1).\n",
    "    f0_class0 = np.random.normal(loc=1.0, scale=1.0, size=n0)\n",
    "    f0_class1 = np.random.normal(loc=10.0, scale=1.0, size=n1)\n",
    "    f0 = np.concatenate([f0_class0, f0_class1])\n",
    "\n",
    "    # Feature 1: Irrelevant noise feature.\n",
    "    # Values drawn from a standard normal distribution regardless of class.\n",
    "    f1 = np.random.normal(loc=0.0, scale=1.0, size=n_samples)\n",
    "\n",
    "    # Feature 2: Relevant discrete feature.\n",
    "    # Class 0 predominantly gets value 10 but with a small chance for 20,\n",
    "    # and class 1 predominantly gets value 20 but with a small chance for 10.\n",
    "    f2_class0 = np.random.choice([10, 20], size=n0, p=[0.9, 0.1])\n",
    "    f2_class1 = np.random.choice([20, 10], size=n1, p=[0.9, 0.1])\n",
    "    f2 = np.concatenate([f2_class0, f2_class1])\n",
    "\n",
    "    # Feature 3: Irrelevant constant feature.\n",
    "    f3 = np.full((n_samples,), 3.0)\n",
    "\n",
    "    # Assemble features into one array.\n",
    "    X = np.column_stack([f0, f1, f2, f3]).astype(np.float32)\n",
    "\n",
    "    # Shuffle the dataset (so the classes are randomly interleaved)\n",
    "    idx = np.arange(n_samples)\n",
    "    np.random.shuffle(idx)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "    return X, y\n",
    "\n",
    "X,y = generate_large_robust_dataset()\n",
    "model = MultiSURF(discrete_limit=4, use_star=True)\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)\n",
    "X,y = generate_large_robust_dataset()\n",
    "model = MultiSURF(discrete_limit=4, backend='cpu', use_star=True)\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)\n",
    "model = ReliefF(discrete_limit=4)\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)\n",
    "model = ReliefF(discrete_limit=4, backend='cpu')\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)\n",
    "model = SURF(discrete_limit=4, use_star=True)\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)\n",
    "model = SURF(discrete_limit=4, backend='cpu', use_star=True)\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "946ed576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using: NVIDIA RTX A2000\n",
      "\n",
      "--- Creating Synthetic Data ---\n",
      "Embedding a pure epistatic interaction between features (25, 75).\n",
      "Rule: Case if (feature_25 == 1) AND (feature_75 == 1)\n",
      "Dataset created with 1600 samples, 200 features.\n",
      "Class distribution: 800 cases, 800 controls.\n",
      "\n",
      "--- Memory Usage Before Fit ---\n",
      "CPU Memory Usage: 342.28 MB\n",
      "GPU Memory Usage: 298.38 MB\n",
      "---------------------------------\n",
      "Starting 5-fold CV to find best 4-way interaction among 64684950 combinations...\n",
      "  Fold 1/5: Best model (0, 25, 75, 149), Test BA: 0.6062\n",
      "  Fold 2/5: Best model (25, 57, 75, 155), Test BA: 0.5656\n",
      "  Fold 3/5: Best model (25, 75, 78, 115), Test BA: 0.5813\n",
      "  Fold 4/5: Best model (23, 25, 75, 94), Test BA: 0.5906\n",
      "  Fold 5/5: Best model (25, 43, 58, 75), Test BA: 0.5219\n",
      "\n",
      "--- Fit Complete ---\n",
      "Best Interaction Model Found: (0, 25, 75, 149)\n",
      "Cross-Validation Consistency (CVC): 1/5\n",
      "Mean Testing Balanced Accuracy: 0.6062\n",
      "\n",
      "--- Memory Usage After Fit ---\n",
      "CPU Memory Usage: 385.96 MB\n",
      "Peak CPU memory during fit: ~43.69 MB\n",
      "GPU Memory Usage: 484.38 MB (reflects data currently on GPU)\n",
      "--------------------------------\n",
      "\n",
      "--- Model Inspection ---\n",
      "INFO: The classifier identified (0, 25, 75, 149) as the strongest signal.\n",
      "\n",
      "--- Prediction Example ---\n",
      "Genotypes of new samples for features (0, 25, 75, 149):\n",
      "[[0 2 1 0]\n",
      " [0 2 0 0]\n",
      " [1 0 0 1]\n",
      " [2 1 1 2]\n",
      " [0 0 1 2]\n",
      " [0 0 0 0]\n",
      " [2 1 0 2]\n",
      " [2 0 0 0]\n",
      " [2 2 0 0]\n",
      " [0 0 2 0]]\n",
      "Predicted classes (0=Low-Risk, 1=High-Risk): [0 0 0 1 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "import psutil\n",
    "from src.fast_select.MDR import GPUMDRClassifier\n",
    "\n",
    "# Check if a GPU is available\n",
    "if not cuda.is_available():\n",
    "    print(\"No CUDA-enabled GPU found. Cannot run the MDR example.\")\n",
    "else:\n",
    "    # --- NEW: Import libraries for memory profiling ---\n",
    "    import os\n",
    "    import psutil\n",
    "\n",
    "    print(f\"CUDA is available. Using: {cuda.get_current_device().name.decode('UTF-8')}\\n\")\n",
    "\n",
    "    # --- NEW: Helper functions to report memory usage ---\n",
    "    def bytes_to_mb(b):\n",
    "        \"\"\"Converts bytes to megabytes.\"\"\"\n",
    "        return round(b / (1024**2), 2)\n",
    "\n",
    "    def get_gpu_mem_usage():\n",
    "        \"\"\"Returns used GPU memory in MB.\"\"\"\n",
    "        free, total = cuda.current_context().get_memory_info()\n",
    "        return bytes_to_mb(total - free)\n",
    "\n",
    "    # Get the current Python process for CPU memory tracking\n",
    "    process = psutil.Process(os.getpid())\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    # 1. Create Synthetic Data with a Known Interaction\n",
    "    print(\"--- Creating Synthetic Data ---\")\n",
    "    n_samples = 1600\n",
    "    n_features = 200\n",
    "    np.random.seed(42)\n",
    "\n",
    "    X = np.random.randint(0, 3, size=(n_samples, n_features), dtype=np.int32)\n",
    "    y = np.zeros(n_samples, dtype=np.int32)\n",
    "\n",
    "    interaction_snps = (25, 75)\n",
    "    print(f\"Embedding a pure epistatic interaction between features {interaction_snps}.\")\n",
    "    print(\"Rule: Case if (feature_25 == 1) AND (feature_75 == 1)\")\n",
    "\n",
    "    risk_mask = (X[:, interaction_snps[0]] == 1) & (X[:, interaction_snps[1]] == 1)\n",
    "    case_indices = np.where(risk_mask)[0]\n",
    "    n_cases_to_set = n_samples // 2\n",
    "    y[case_indices] = 1\n",
    "    current_cases = np.sum(y)\n",
    "    if current_cases < n_cases_to_set:\n",
    "        n_needed = n_cases_to_set - current_cases\n",
    "        potential_indices = np.where(y == 0)[0]\n",
    "        promo_indices = np.random.choice(potential_indices, n_needed, replace=False)\n",
    "        y[promo_indices] = 1\n",
    "\n",
    "    print(f\"Dataset created with {n_samples} samples, {n_features} features.\")\n",
    "    print(f\"Class distribution: {np.sum(y==1)} cases, {np.sum(y==0)} controls.\\n\")\n",
    "\n",
    "\n",
    "    # 2. Instantiate and Run the GPUMDRClassifier\n",
    "    mdr = GPUMDRClassifier(k=4, cv=5)\n",
    "\n",
    "    # --- NEW: Memory reporting before fit ---\n",
    "    print(\"--- Memory Usage Before Fit ---\")\n",
    "    mem_before_cpu = process.memory_info().rss\n",
    "    print(f\"CPU Memory Usage: {bytes_to_mb(mem_before_cpu)} MB\")\n",
    "    print(f\"GPU Memory Usage: {get_gpu_mem_usage()} MB\")\n",
    "    print(\"-\" * 33)\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # Fit the model\n",
    "    mdr.fit(X, y)\n",
    "\n",
    "    # --- NEW: Memory reporting after fit ---\n",
    "    print(\"\\n--- Memory Usage After Fit ---\")\n",
    "    mem_after_cpu = process.memory_info().rss\n",
    "    print(f\"CPU Memory Usage: {bytes_to_mb(mem_after_cpu)} MB\")\n",
    "    print(f\"Peak CPU memory during fit: ~{bytes_to_mb(mem_after_cpu - mem_before_cpu)} MB\")\n",
    "    print(f\"GPU Memory Usage: {get_gpu_mem_usage()} MB (reflects data currently on GPU)\")\n",
    "    print(\"-\" * 32)\n",
    "\n",
    "    print(\"\\n--- Model Inspection ---\")\n",
    "    if mdr.best_interaction_ == interaction_snps or mdr.best_interaction_ == tuple(reversed(interaction_snps)):\n",
    "        print(f\"SUCCESS: The classifier correctly identified the embedded interaction: {mdr.best_interaction_}\")\n",
    "    else:\n",
    "        print(f\"INFO: The classifier identified {mdr.best_interaction_} as the strongest signal.\")\n",
    "\n",
    "    print(\"\\n--- Prediction Example ---\")\n",
    "    X_new = np.random.randint(0, 3, size=(10, n_features), dtype=np.int32)\n",
    "    X_new[3, interaction_snps[0]] = 1\n",
    "    X_new[3, interaction_snps[1]] = 1\n",
    "\n",
    "    y_pred = mdr.predict(X_new)\n",
    "    print(f\"Genotypes of new samples for features {mdr.best_interaction_}:\\n{X_new[:, mdr.best_interaction_]}\")\n",
    "    print(f\"Predicted classes (0=Low-Risk, 1=High-Risk): {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f4adc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/galynch/snap/snapd-desktop-integration/253/Desktop/FastSelect\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816ecad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
