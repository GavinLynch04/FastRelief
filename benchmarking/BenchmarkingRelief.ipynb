{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5fcbaf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from memory_profiler import memory_usage\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# --- Your other imports ---\n",
    "from skrebate import SURF, ReliefF\n",
    "from skrebate import MultiSURF as SkrebateMultiSURF\n",
    "\n",
    "from src.fast_select.MultiSURF import MultiSURF as FastMultiSURF\n",
    "from src.fast_select.ReliefF import ReliefF as FastReliefF\n",
    "from src.fast_select.SURF import SURF as FastSURF\n",
    "\n",
    "# --- GPU Detection ---\n",
    "try:\n",
    "    from numba import cuda\n",
    "    GPU_AVAILABLE = cuda.is_available()\n",
    "except (ImportError, cuda.cudadrv.error.CudaSupportError):\n",
    "    GPU_AVAILABLE = False\n",
    "\n",
    "# --- Benchmark Configuration ---\n",
    "P_DOMINANT_SCENARIOS = {\n",
    "    \"name\": \"p >> n (Features Dominant)\",\n",
    "    \"fixed_param\": \"n_samples\", \"fixed_value\": 500,\n",
    "    \"varied_param\": \"n_features\", \"varied_range\": [100, 200, 300, 400, 500]\n",
    "}\n",
    "N_DOMINANT_SCENARIOS = {\n",
    "    \"name\": \"n >> p (Samples Dominant)\",\n",
    "    \"fixed_param\": \"n_features\", \"fixed_value\": 100,\n",
    "    \"varied_param\": \"n_samples\", \"varied_range\": [500, 1000, 1500, 2000, 2500]\n",
    "}\n",
    "N_FEATURES_TO_SELECT = 10\n",
    "N_REPEATS = 3 # Increase repeats for more stable results\n",
    "\n",
    "# --- Estimators to Test ---\n",
    "estimators = {\n",
    "    # skrebate estimators\n",
    "    \"skrebate.ReliefF\": ReliefF(n_features_to_select=N_FEATURES_TO_SELECT,\n",
    "                                n_neighbors=10, n_jobs=-1),\n",
    "    \"skrebate.SURF\": SURF(n_features_to_select=N_FEATURES_TO_SELECT, n_jobs=-1),\n",
    "    \"skrebate.MultiSURF\": SkrebateMultiSURF(n_features_to_select=N_FEATURES_TO_SELECT,\n",
    "                                            n_jobs=-1),\n",
    "    # fast-select CPU estimators\n",
    "    \"fast_select.ReliefF (CPU)\": FastReliefF(n_features_to_select=N_FEATURES_TO_SELECT,\n",
    "                                             n_neighbors=10, backend='cpu', n_jobs=-1),\n",
    "    \"fast_select.SURF (CPU)\": FastSURF(n_features_to_select=N_FEATURES_TO_SELECT,\n",
    "                                       n_jobs=-1),\n",
    "    \"fast_select.MultiSURF (CPU)\": FastMultiSURF(n_features_to_select=N_FEATURES_TO_SELECT,\n",
    "                                                 backend='cpu', n_jobs=-1),\n",
    "}\n",
    "if GPU_AVAILABLE:\n",
    "    print(\"NVIDIA GPU detected. Including GPU benchmarks.\")\n",
    "    estimators.update({\n",
    "        \"fast_select.ReliefF (GPU)\": FastReliefF(n_features_to_select=N_FEATURES_TO_SELECT,\n",
    "                                                 n_neighbors=10, backend='gpu'),\n",
    "        \"fast_select.SURF (GPU)\": FastSURF(n_features_to_select=N_FEATURES_TO_SELECT,\n",
    "                                           backend='gpu'),\n",
    "        \"fast_select.MultiSURF (GPU)\": FastMultiSURF(n_features_to_select=N_FEATURES_TO_SELECT,\n",
    "                                                     backend='gpu'),\n",
    "    })\n",
    "else:\n",
    "    print(\"No NVIDIA GPU detected. Skipping GPU benchmarks.\")\n",
    "\n",
    "# --- CORRECTED BENCHMARK FUNCTION ---\n",
    "def run_single_benchmark(estimator, X, y):\n",
    "    \"\"\"\n",
    "    Measures runtime and peak memory usage of a single estimator fit.\n",
    "    This version performs only ONE execution and correctly measures GPU memory.\n",
    "    \"\"\"\n",
    "    is_gpu_estimator = hasattr(estimator, 'backend') and estimator.backend == 'gpu'\n",
    "\n",
    "    # Use a lambda to wrap the fit call\n",
    "    fit_func = lambda: estimator.fit(X, y)\n",
    "\n",
    "    # --- Memory Measurement ---\n",
    "    peak_mem_mb = 0\n",
    "    if is_gpu_estimator:\n",
    "        # For GPU, we measure VRAM usage directly.\n",
    "        # This requires the fit function to be run inside the context.\n",
    "        ctx = cuda.current_context()\n",
    "        start_mem = ctx.get_memory_info().free\n",
    "        fit_func() # Run the function\n",
    "        end_mem = ctx.get_memory_info().free\n",
    "        # Peak memory is the reduction in free memory.\n",
    "        peak_mem_mb = (start_mem - end_mem) / (1024**2)\n",
    "    else:\n",
    "        # For CPU, memory_profiler works perfectly.\n",
    "        mem_samples = memory_usage(fit_func, interval=0.1)\n",
    "        peak_mem_mb = max(mem_samples)\n",
    "\n",
    "    # --- Runtime Measurement ---\n",
    "    # Since the function has already been run once for memory profiling,\n",
    "    # we time a second run to get a pure execution time without JIT overhead.\n",
    "    # This is now a consistent measurement.\n",
    "    start_time = time.perf_counter()\n",
    "    fit_func()\n",
    "    end_time = time.perf_counter()\n",
    "    runtime = end_time - start_time\n",
    "\n",
    "    return runtime, peak_mem_mb\n",
    "\n",
    "def warmup_jit_compilers(estimators_dict):\n",
    "    \"\"\"Performs a 'warm-up' run on a small dataset to compile JIT functions.\"\"\"\n",
    "    print(\"\\n--- Warming up JIT compilers ---\")\n",
    "    X_warmup, y_warmup = make_classification(n_samples=20, n_features=20, random_state=42)\n",
    "    for name, estimator in estimators_dict.items():\n",
    "        # More robust check for our custom estimators\n",
    "        if \"fast_select\" in name:\n",
    "            print(f\"  Warming up {name}...\")\n",
    "            try:\n",
    "                # Use a fresh clone for warmup\n",
    "                clone(estimator).fit(X_warmup, y_warmup)\n",
    "            except Exception as e:\n",
    "                warnings.warn(f\"  > Warm-up FAILED for {name}. Reason: {type(e).__name__}: {e}\")\n",
    "    print(\"--- Warm-up complete ---\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run all benchmark scenarios.\"\"\"\n",
    "    results = []\n",
    "    warmup_jit_compilers(estimators)\n",
    "\n",
    "    scenarios = [P_DOMINANT_SCENARIOS, N_DOMINANT_SCENARIOS]\n",
    "\n",
    "    for scenario_params in scenarios:\n",
    "        scenario_name = scenario_params[\"name\"]\n",
    "        print(f\"\\n--- Running Scenario: {scenario_name} ---\")\n",
    "\n",
    "        fixed_param = scenario_params[\"fixed_param\"]\n",
    "        varied_param = scenario_params[\"varied_param\"]\n",
    "\n",
    "        for varied_value in scenario_params[\"varied_range\"]:\n",
    "            # Set up dataset dimensions for this run\n",
    "            if fixed_param == \"n_samples\":\n",
    "                n_samples = scenario_params[\"fixed_value\"]\n",
    "                n_features = varied_value\n",
    "            else:\n",
    "                n_samples = varied_value\n",
    "                n_features = scenario_params[\"fixed_value\"]\n",
    "\n",
    "            print(f\"\\nGenerating data: {n_samples} samples, {n_features} features\")\n",
    "            X, y = make_classification(n_samples=n_samples, n_features=n_features, n_informative=20,\n",
    "                                       n_redundant=50, random_state=42)\n",
    "\n",
    "            for name, base_estimator in estimators.items():\n",
    "                for i in range(N_REPEATS):\n",
    "                    print(f\"  Benchmarking {name} (Run {i+1}/{N_REPEATS})...\")\n",
    "                    try:\n",
    "                        estimator = clone(base_estimator)\n",
    "                        runtime, peak_mem = run_single_benchmark(estimator, X, y)\n",
    "                        results.append({\n",
    "                            \"scenario\": scenario_name, \"algorithm\": name,\n",
    "                            \"n_samples\": n_samples, \"n_features\": n_features,\n",
    "                            \"runtime_sec\": runtime, \"peak_memory_mb\": peak_mem\n",
    "                        })\n",
    "                    except Exception:\n",
    "                        warnings.warn(f\"  > FAILED: {name} on {n_samples}x{n_features}.\",\n",
    "                                      \"Reason: {type(e).__name__}: {e}\", UserWarning)\n",
    "\n",
    "    # --- Save results to CSV ---\n",
    "    df = pd.DataFrame(results)\n",
    "    output_file = \"benchmark_results_with_memory.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nBenchmarking complete. Results saved to '{output_file}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05174a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 099564b] updated TuRF slightly\n",
      "Enumerating objects: 32, done.\n",
      "Counting objects: 100% (24/24), done.\n",
      "Delta compression using up to 20 threads\n",
      "Compressing objects: 100% (13/13), done.\n",
      "Writing objects: 100% (14/14), 3.20 KiB | 819.00 KiB/s, done.\n",
      "Total 14 (delta 10), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (10/10), completed with 7 local objects.\u001b[K\n",
      "To https://github.com/GavinLynch04/FastSelect.git\n",
      "   6d6f6c5..099564b  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git commit -a -m \"updated TuRF slightly\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d2c79e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf dist/ build/ fast_select.egg-info/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd8cf797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m* Creating isolated environment: venv+pip...\u001b[0m\n",
      "\u001b[1m* Installing packages in isolated environment:\u001b[0m\n",
      "  - setuptools>=61.0\n",
      "\u001b[1m* Getting build dependencies for sdist...\u001b[0m\n",
      "running egg_info\n",
      "writing src/fast_select.egg-info/PKG-INFO\n",
      "writing dependency_links to src/fast_select.egg-info/dependency_links.txt\n",
      "writing requirements to src/fast_select.egg-info/requires.txt\n",
      "writing top-level names to src/fast_select.egg-info/top_level.txt\n",
      "reading manifest file 'src/fast_select.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'src/fast_select.egg-info/SOURCES.txt'\n",
      "\u001b[1m* Building sdist...\u001b[0m\n",
      "running sdist\n",
      "running egg_info\n",
      "writing src/fast_select.egg-info/PKG-INFO\n",
      "writing dependency_links to src/fast_select.egg-info/dependency_links.txt\n",
      "writing requirements to src/fast_select.egg-info/requires.txt\n",
      "writing top-level names to src/fast_select.egg-info/top_level.txt\n",
      "reading manifest file 'src/fast_select.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'src/fast_select.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating fast_select-0.1.3\n",
      "creating fast_select-0.1.3/src/fast_select\n",
      "creating fast_select-0.1.3/src/fast_select.egg-info\n",
      "creating fast_select-0.1.3/tests\n",
      "copying files to fast_select-0.1.3...\n",
      "copying LICENSE -> fast_select-0.1.3\n",
      "copying README.md -> fast_select-0.1.3\n",
      "copying pyproject.toml -> fast_select-0.1.3\n",
      "copying src/fast_select/MultiSURF.py -> fast_select-0.1.3/src/fast_select\n",
      "copying src/fast_select/ReliefF.py -> fast_select-0.1.3/src/fast_select\n",
      "copying src/fast_select/SURF.py -> fast_select-0.1.3/src/fast_select\n",
      "copying src/fast_select/TuRF.py -> fast_select-0.1.3/src/fast_select\n",
      "copying src/fast_select/__init__.py -> fast_select-0.1.3/src/fast_select\n",
      "copying src/fast_select.egg-info/PKG-INFO -> fast_select-0.1.3/src/fast_select.egg-info\n",
      "copying src/fast_select.egg-info/SOURCES.txt -> fast_select-0.1.3/src/fast_select.egg-info\n",
      "copying src/fast_select.egg-info/dependency_links.txt -> fast_select-0.1.3/src/fast_select.egg-info\n",
      "copying src/fast_select.egg-info/requires.txt -> fast_select-0.1.3/src/fast_select.egg-info\n",
      "copying src/fast_select.egg-info/top_level.txt -> fast_select-0.1.3/src/fast_select.egg-info\n",
      "copying tests/test_multisurf.py -> fast_select-0.1.3/tests\n",
      "copying tests/test_relieff.py -> fast_select-0.1.3/tests\n",
      "copying tests/test_surf.py -> fast_select-0.1.3/tests\n",
      "copying src/fast_select.egg-info/SOURCES.txt -> fast_select-0.1.3/src/fast_select.egg-info\n",
      "Writing fast_select-0.1.3/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'fast_select-0.1.3' (and everything under it)\n",
      "\u001b[1m* Building wheel from sdist\u001b[0m\n",
      "\u001b[1m* Creating isolated environment: venv+pip...\u001b[0m\n",
      "\u001b[1m* Installing packages in isolated environment:\u001b[0m\n",
      "  - setuptools>=61.0\n",
      "\u001b[1m* Getting build dependencies for wheel...\u001b[0m\n",
      "running egg_info\n",
      "writing src/fast_select.egg-info/PKG-INFO\n",
      "writing dependency_links to src/fast_select.egg-info/dependency_links.txt\n",
      "writing requirements to src/fast_select.egg-info/requires.txt\n",
      "writing top-level names to src/fast_select.egg-info/top_level.txt\n",
      "reading manifest file 'src/fast_select.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'src/fast_select.egg-info/SOURCES.txt'\n",
      "\u001b[1m* Building wheel...\u001b[0m\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build/lib/fast_select\n",
      "copying src/fast_select/TuRF.py -> build/lib/fast_select\n",
      "copying src/fast_select/__init__.py -> build/lib/fast_select\n",
      "copying src/fast_select/ReliefF.py -> build/lib/fast_select\n",
      "copying src/fast_select/MultiSURF.py -> build/lib/fast_select\n",
      "copying src/fast_select/SURF.py -> build/lib/fast_select\n",
      "running egg_info\n",
      "writing src/fast_select.egg-info/PKG-INFO\n",
      "writing dependency_links to src/fast_select.egg-info/dependency_links.txt\n",
      "writing requirements to src/fast_select.egg-info/requires.txt\n",
      "writing top-level names to src/fast_select.egg-info/top_level.txt\n",
      "reading manifest file 'src/fast_select.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'src/fast_select.egg-info/SOURCES.txt'\n",
      "installing to build/bdist.linux-x86_64/wheel\n",
      "running install\n",
      "running install_lib\n",
      "creating build/bdist.linux-x86_64/wheel\n",
      "creating build/bdist.linux-x86_64/wheel/fast_select\n",
      "copying build/lib/fast_select/TuRF.py -> build/bdist.linux-x86_64/wheel/./fast_select\n",
      "copying build/lib/fast_select/__init__.py -> build/bdist.linux-x86_64/wheel/./fast_select\n",
      "copying build/lib/fast_select/ReliefF.py -> build/bdist.linux-x86_64/wheel/./fast_select\n",
      "copying build/lib/fast_select/MultiSURF.py -> build/bdist.linux-x86_64/wheel/./fast_select\n",
      "copying build/lib/fast_select/SURF.py -> build/bdist.linux-x86_64/wheel/./fast_select\n",
      "running install_egg_info\n",
      "Copying src/fast_select.egg-info to build/bdist.linux-x86_64/wheel/./fast_select-0.1.3-py3.10.egg-info\n",
      "running install_scripts\n",
      "creating build/bdist.linux-x86_64/wheel/fast_select-0.1.3.dist-info/WHEEL\n",
      "creating '/home/galynch/snap/snapd-desktop-integration/253/Desktop/FastSelect/dist/.tmp-zemz1d3a/fast_select-0.1.3-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
      "adding 'fast_select/MultiSURF.py'\n",
      "adding 'fast_select/ReliefF.py'\n",
      "adding 'fast_select/SURF.py'\n",
      "adding 'fast_select/TuRF.py'\n",
      "adding 'fast_select/__init__.py'\n",
      "adding 'fast_select-0.1.3.dist-info/licenses/LICENSE'\n",
      "adding 'fast_select-0.1.3.dist-info/METADATA'\n",
      "adding 'fast_select-0.1.3.dist-info/WHEEL'\n",
      "adding 'fast_select-0.1.3.dist-info/top_level.txt'\n",
      "adding 'fast_select-0.1.3.dist-info/RECORD'\n",
      "removing build/bdist.linux-x86_64/wheel\n",
      "\u001b[1m\u001b[92mSuccessfully built \u001b[4mfast_select-0.1.3.tar.gz\u001b[0m\u001b[1m\u001b[92m and \u001b[4mfast_select-0.1.3-py3-none-any.whl\u001b[0m\u001b[1m\u001b[92m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bae9eaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading distributions to https://test.pypi.org/legacy/\n",
      "\u001b[34mINFO    \u001b[0m dist/fast_select-0.1.3-py3-none-any.whl (20.1 KB)                      \n",
      "\u001b[34mINFO    \u001b[0m dist/fast_select-0.1.3.tar.gz (22.1 KB)                                \n",
      "\u001b[34mINFO    \u001b[0m username set by command options                                        \n",
      "\u001b[34mINFO    \u001b[0m password set by command options                                        \n",
      "\u001b[34mINFO    \u001b[0m username: __token__                                                    \n",
      "\u001b[34mINFO    \u001b[0m password: <hidden>                                                     \n",
      "Uploading fast_select-0.1.3-py3-none-any.whl\n",
      "\u001b[2K\u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 kB\u001b[0m • \u001b[33m00:00\u001b[0m • \u001b[31m166.4 MB/s\u001b[0m\n",
      "\u001b[?25h\u001b[34mINFO    \u001b[0m Response from https://test.pypi.org/legacy/:                           \n",
      "         200 OK                                                                 \n",
      "\u001b[34mINFO    \u001b[0m <html>                                                                 \n",
      "          <head>                                                                \n",
      "           <title>200 OK</title>                                                \n",
      "          </head>                                                               \n",
      "          <body>                                                                \n",
      "           <h1>200 OK</h1>                                                      \n",
      "           <br/><br/>                                                           \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "          </body>                                                               \n",
      "         </html>                                                                \n",
      "Uploading fast_select-0.1.3.tar.gz\n",
      "\u001b[2K\u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 kB\u001b[0m • \u001b[33m00:00\u001b[0m • \u001b[31m205.6 MB/s\u001b[0m\n",
      "\u001b[?25h\u001b[34mINFO    \u001b[0m Response from https://test.pypi.org/legacy/:                           \n",
      "         200 OK                                                                 \n",
      "\u001b[34mINFO    \u001b[0m <html>                                                                 \n",
      "          <head>                                                                \n",
      "           <title>200 OK</title>                                                \n",
      "          </head>                                                               \n",
      "          <body>                                                                \n",
      "           <h1>200 OK</h1>                                                      \n",
      "           <br/><br/>                                                           \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "          </body>                                                               \n",
      "         </html>                                                                \n",
      "\n",
      "\u001b[32mView at:\u001b[0m\n",
      "https://test.pypi.org/project/fast-select/0.1.3/\n"
     ]
    }
   ],
   "source": [
    "!TWINE_USERNAME=__token__ TWINE_PASSWORD= python3 -m twine upload --repository testpypi dist/* --verbose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946ed576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_benchmarks.py\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_scenario(df, scenario_name, x_axis, y_axis, y_label,\n",
    "                  title, filename, use_log_scale=True):\n",
    "    \"\"\"\n",
    "    Generic helper function to generate and save a plot for a given scenario.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The full results dataframe.\n",
    "        scenario_name (str): The name of the scenario to filter for (e.g., 'p >> n').\n",
    "        x_axis (str): The column name for the x-axis (e.g., 'n_features').\n",
    "        y_axis (str): The column name for the y-axis (e.g., 'runtime_sec').\n",
    "        y_label (str): The descriptive label for the y-axis.\n",
    "        title (str): The main title for the plot.\n",
    "        filename (str): The output filename for the saved plot.\n",
    "        use_log_scale (bool): Whether to use a logarithmic scale for the y-axis.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame for the specific scenario\n",
    "    scenario_df = df[df['scenario'] == scenario_name].copy()\n",
    "\n",
    "    # Create a new figure and axes for the plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Use seaborn for a clean, publication-quality line plot\n",
    "    sns.lineplot(\n",
    "        data=scenario_df,\n",
    "        x=x_axis,\n",
    "        y=y_axis,\n",
    "        hue='algorithm',\n",
    "        marker='o',\n",
    "        linewidth=2.5,\n",
    "        errorbar='sd' # 'ci' is deprecated; 'errorbar' is the new standard\n",
    "    )\n",
    "\n",
    "    # Set plot properties\n",
    "    plt.title(title, fontsize=18, fontweight='bold', pad=20)\n",
    "    plt.xlabel(x_axis.replace('_', ' ').title(), fontsize=14)\n",
    "    plt.ylabel(y_label, fontsize=14)\n",
    "\n",
    "    if use_log_scale:\n",
    "        plt.yscale('log')\n",
    "\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
    "    plt.legend(title='Algorithm', fontsize=11, title_fontsize=13)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Plot saved to '{filename}'\")\n",
    "    plt.close() # Close the figure to free up memory\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to load results and generate all plots.\"\"\"\n",
    "    input_file = \"benchmark_results_with_memory.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(input_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: '{input_file}' not found.\", file=sys.stderr)\n",
    "        print(\"Please run the updated benchmark script first.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Validate that the necessary columns exist\n",
    "    required_cols = ['scenario', 'algorithm', 'n_samples', 'n_features',\n",
    "                     'runtime_sec', 'peak_memory_mb']\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        print(f\"Error: The CSV file '{input_file}' is missing required columns.\",\n",
    "              file=sys.stderr)\n",
    "        print(f\"Expected columns: {required_cols}\", file=sys.stderr)\n",
    "        print(f\"Found columns: {list(df.columns)}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Use a professional plot style\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    # --- Runtime Plots ---\n",
    "    print(\"\\n--- Generating Runtime Plots ---\")\n",
    "    plot_scenario(\n",
    "        df=df,\n",
    "        scenario_name='p >> n (Features Dominant)',\n",
    "        x_axis='n_features',\n",
    "        y_axis='runtime_sec',\n",
    "        y_label=\"Runtime (seconds, log scale)\",\n",
    "        title='Benchmark: Runtime vs. Number of Features (p >> n)\\n(n_samples fixed)',\n",
    "        filename='benchmark_p_dominant_runtime.png',\n",
    "        use_log_scale=True\n",
    "    )\n",
    "    plot_scenario(\n",
    "        df=df,\n",
    "        scenario_name='n >> p (Samples Dominant)',\n",
    "        x_axis='n_samples',\n",
    "        y_axis='runtime_sec',\n",
    "        y_label=\"Runtime (seconds, log scale)\",\n",
    "        title='Benchmark: Runtime vs. Number of Samples (n >> p)\\n(n_features fixed)',\n",
    "        filename='benchmark_n_dominant_runtime.png',\n",
    "        use_log_scale=True\n",
    "    )\n",
    "\n",
    "    # --- Memory Usage Plots ---\n",
    "    print(\"\\n--- Generating Memory Usage Plots ---\")\n",
    "    plot_scenario(\n",
    "        df=df,\n",
    "        scenario_name='p >> n (Features Dominant)',\n",
    "        x_axis='n_features',\n",
    "        y_axis='peak_memory_mb',\n",
    "        y_label=\"Peak Memory Usage (MB, log scale)\",\n",
    "        title='Benchmark: Memory vs. Number of Features (p >> n)\\n(n_samples fixed)',\n",
    "        filename='benchmark_p_dominant_memory.png',\n",
    "        use_log_scale=True # Memory can also vary greatly, log scale is often useful\n",
    "    )\n",
    "    plot_scenario(\n",
    "        df=df,\n",
    "        scenario_name='n >> p (Samples Dominant)',\n",
    "        x_axis='n_samples',\n",
    "        y_axis='peak_memory_mb',\n",
    "        y_label=\"Peak Memory Usage (MB, log scale)\",\n",
    "        title='Benchmark: Memory vs. Number of Samples (n >> p)\\n(n_features fixed)',\n",
    "        filename='benchmark_n_dominant_memory.png',\n",
    "        use_log_scale=True\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4adc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
