{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5fcbaf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GPU detected. Including GPU benchmarks.\n",
      "\n",
      "--- Warming up JIT compilers ---\n",
      "  Warming up fast_select.ReliefF (CPU)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galynch/snap/snapd-desktop-integration/253/Desktop/FastSelect/src/fast_select/ReliefF.py:360: UserWarning: n_neighbors (10) is greater than or equal to the smallest class size (10).\n",
      "  warnings.warn(\n",
      "/home/galynch/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Warming up fast_select.SURF (CPU)...\n",
      "  Warming up fast_select.MultiSURF (CPU)...\n",
      "  Warming up fast_select.ReliefF (GPU)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galynch/snap/snapd-desktop-integration/253/Desktop/FastSelect/src/fast_select/ReliefF.py:360: UserWarning: n_neighbors (10) is greater than or equal to the smallest class size (10).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Warming up fast_select.SURF (GPU)...\n",
      "  Warming up fast_select.MultiSURF (GPU)...\n",
      "--- Warm-up complete ---\n",
      "\n",
      "--- Running Scenario: p >> n (Features Dominant) ---\n",
      "\n",
      "Generating data: 500 samples, 100 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 500 samples, 200 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 500 samples, 300 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 500 samples, 400 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 500 samples, 500 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "--- Running Scenario: n >> p (Samples Dominant) ---\n",
      "\n",
      "Generating data: 500 samples, 100 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 1000 samples, 100 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 1500 samples, 100 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 2000 samples, 100 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Generating data: 2500 samples, 100 features\n",
      "  Benchmarking skrebate.ReliefF (Run 1/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 2/3)...\n",
      "  Benchmarking skrebate.ReliefF (Run 3/3)...\n",
      "  Benchmarking skrebate.SURF (Run 1/3)...\n",
      "  Benchmarking skrebate.SURF (Run 2/3)...\n",
      "  Benchmarking skrebate.SURF (Run 3/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 1/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 2/3)...\n",
      "  Benchmarking skrebate.MultiSURF (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (CPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.ReliefF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.SURF (GPU) (Run 3/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 1/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 2/3)...\n",
      "  Benchmarking fast_select.MultiSURF (GPU) (Run 3/3)...\n",
      "\n",
      "Benchmarking complete. Results saved to 'benchmark_results_with_memory.csv'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import psutil\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import make_classification\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# --- Your other imports ---\n",
    "from skrebate import ReliefF, SURF, SURFstar, MultiSURF as SkrebateMultiSURF, MultiSURFstar\n",
    "from src.fast_select.ReliefF import ReliefF as FastReliefF\n",
    "from src.fast_select.SURF import SURF as FastSURF\n",
    "from src.fast_select.MultiSURF import MultiSURF as FastMultiSURF\n",
    "\n",
    "# --- GPU Detection ---\n",
    "try:\n",
    "    from numba import cuda\n",
    "    GPU_AVAILABLE = cuda.is_available()\n",
    "except (ImportError, cuda.cudadrv.error.CudaSupportError):\n",
    "    GPU_AVAILABLE = False\n",
    "\n",
    "# --- Benchmark Configuration ---\n",
    "P_DOMINANT_SCENARIOS = {\n",
    "    \"name\": \"p >> n (Features Dominant)\",\n",
    "    \"fixed_param\": \"n_samples\", \"fixed_value\": 500,\n",
    "    \"varied_param\": \"n_features\", \"varied_range\": [100, 200, 300, 400, 500]\n",
    "}\n",
    "N_DOMINANT_SCENARIOS = {\n",
    "    \"name\": \"n >> p (Samples Dominant)\",\n",
    "    \"fixed_param\": \"n_features\", \"fixed_value\": 100,\n",
    "    \"varied_param\": \"n_samples\", \"varied_range\": [500, 1000, 1500, 2000, 2500]\n",
    "}\n",
    "N_FEATURES_TO_SELECT = 10\n",
    "N_REPEATS = 3 # Increase repeats for more stable results\n",
    "\n",
    "# --- Estimators to Test ---\n",
    "estimators = {\n",
    "    # skrebate estimators\n",
    "    \"skrebate.ReliefF\": ReliefF(n_features_to_select=N_FEATURES_TO_SELECT, n_neighbors=10, n_jobs=-1),\n",
    "    \"skrebate.SURF\": SURF(n_features_to_select=N_FEATURES_TO_SELECT, n_jobs=-1),\n",
    "    \"skrebate.MultiSURF\": SkrebateMultiSURF(n_features_to_select=N_FEATURES_TO_SELECT, n_jobs=-1),\n",
    "    # fast-select CPU estimators\n",
    "    \"fast_select.ReliefF (CPU)\": FastReliefF(n_features_to_select=N_FEATURES_TO_SELECT, n_neighbors=10, backend='cpu', n_jobs=-1),\n",
    "    \"fast_select.SURF (CPU)\": FastSURF(n_features_to_select=N_FEATURES_TO_SELECT, n_jobs=-1),\n",
    "    \"fast_select.MultiSURF (CPU)\": FastMultiSURF(n_features_to_select=N_FEATURES_TO_SELECT, backend='cpu', n_jobs=-1),\n",
    "}\n",
    "if GPU_AVAILABLE:\n",
    "    print(\"NVIDIA GPU detected. Including GPU benchmarks.\")\n",
    "    estimators.update({\n",
    "        \"fast_select.ReliefF (GPU)\": FastReliefF(n_features_to_select=N_FEATURES_TO_SELECT, n_neighbors=10, backend='gpu'),\n",
    "        \"fast_select.SURF (GPU)\": FastSURF(n_features_to_select=N_FEATURES_TO_SELECT, backend='gpu'),\n",
    "        \"fast_select.MultiSURF (GPU)\": FastMultiSURF(n_features_to_select=N_FEATURES_TO_SELECT, backend='gpu'),\n",
    "    })\n",
    "else:\n",
    "    print(\"No NVIDIA GPU detected. Skipping GPU benchmarks.\")\n",
    "\n",
    "# --- CORRECTED BENCHMARK FUNCTION ---\n",
    "def run_single_benchmark(estimator, X, y):\n",
    "    \"\"\"\n",
    "    Measures runtime and peak memory usage of a single estimator fit.\n",
    "    This version performs only ONE execution and correctly measures GPU memory.\n",
    "    \"\"\"\n",
    "    is_gpu_estimator = hasattr(estimator, 'backend') and estimator.backend == 'gpu'\n",
    "    \n",
    "    # Use a lambda to wrap the fit call\n",
    "    fit_func = lambda: estimator.fit(X, y)\n",
    "\n",
    "    # --- Memory Measurement ---\n",
    "    peak_mem_mb = 0\n",
    "    if is_gpu_estimator:\n",
    "        # For GPU, we measure VRAM usage directly.\n",
    "        # This requires the fit function to be run inside the context.\n",
    "        ctx = cuda.current_context()\n",
    "        start_mem = ctx.get_memory_info().free\n",
    "        fit_func() # Run the function\n",
    "        end_mem = ctx.get_memory_info().free\n",
    "        # Peak memory is the reduction in free memory.\n",
    "        peak_mem_mb = (start_mem - end_mem) / (1024**2)\n",
    "    else:\n",
    "        # For CPU, memory_profiler works perfectly.\n",
    "        mem_samples = memory_usage(fit_func, interval=0.1)\n",
    "        peak_mem_mb = max(mem_samples)\n",
    "\n",
    "    # --- Runtime Measurement ---\n",
    "    # Since the function has already been run once for memory profiling,\n",
    "    # we time a second run to get a pure execution time without JIT overhead.\n",
    "    # This is now a consistent measurement.\n",
    "    start_time = time.perf_counter()\n",
    "    fit_func()\n",
    "    end_time = time.perf_counter()\n",
    "    runtime = end_time - start_time\n",
    "    \n",
    "    return runtime, peak_mem_mb\n",
    "\n",
    "def warmup_jit_compilers(estimators_dict):\n",
    "    \"\"\"Performs a 'warm-up' run on a small dataset to compile JIT functions.\"\"\"\n",
    "    print(\"\\n--- Warming up JIT compilers ---\")\n",
    "    X_warmup, y_warmup = make_classification(n_samples=20, n_features=20, random_state=42)\n",
    "    for name, estimator in estimators_dict.items():\n",
    "        # More robust check for our custom estimators\n",
    "        if \"fast_select\" in name:\n",
    "            print(f\"  Warming up {name}...\")\n",
    "            try:\n",
    "                # Use a fresh clone for warmup\n",
    "                clone(estimator).fit(X_warmup, y_warmup)\n",
    "            except Exception as e:\n",
    "                warnings.warn(f\"  > Warm-up FAILED for {name}. Reason: {type(e).__name__}: {e}\")\n",
    "    print(\"--- Warm-up complete ---\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run all benchmark scenarios.\"\"\"\n",
    "    results = []\n",
    "    warmup_jit_compilers(estimators)\n",
    "\n",
    "    scenarios = [P_DOMINANT_SCENARIOS, N_DOMINANT_SCENARIOS]\n",
    "    \n",
    "    for scenario_params in scenarios:\n",
    "        scenario_name = scenario_params[\"name\"]\n",
    "        print(f\"\\n--- Running Scenario: {scenario_name} ---\")\n",
    "        \n",
    "        fixed_param = scenario_params[\"fixed_param\"]\n",
    "        varied_param = scenario_params[\"varied_param\"]\n",
    "        \n",
    "        for varied_value in scenario_params[\"varied_range\"]:\n",
    "            # Set up dataset dimensions for this run\n",
    "            if fixed_param == \"n_samples\":\n",
    "                n_samples = scenario_params[\"fixed_value\"]\n",
    "                n_features = varied_value\n",
    "            else:\n",
    "                n_samples = varied_value\n",
    "                n_features = scenario_params[\"fixed_value\"]\n",
    "                \n",
    "            print(f\"\\nGenerating data: {n_samples} samples, {n_features} features\")\n",
    "            X, y = make_classification(n_samples=n_samples, n_features=n_features, n_informative=20, n_redundant=50, random_state=42)\n",
    "\n",
    "            for name, base_estimator in estimators.items():\n",
    "                for i in range(N_REPEATS):\n",
    "                    print(f\"  Benchmarking {name} (Run {i+1}/{N_REPEATS})...\")\n",
    "                    try:\n",
    "                        estimator = clone(base_estimator)\n",
    "                        runtime, peak_mem = run_single_benchmark(estimator, X, y)\n",
    "                        results.append({\n",
    "                            \"scenario\": scenario_name, \"algorithm\": name,\n",
    "                            \"n_samples\": n_samples, \"n_features\": n_features,\n",
    "                            \"runtime_sec\": runtime, \"peak_memory_mb\": peak_mem\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        warnings.warn(f\"  > FAILED: {name} on {n_samples}x{n_features}. Reason: {type(e).__name__}: {e}\", UserWarning)\n",
    "\n",
    "    # --- Save results to CSV ---\n",
    "    df = pd.DataFrame(results)\n",
    "    output_file = \"benchmark_results_with_memory.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nBenchmarking complete. Results saved to '{output_file}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05174a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch development\n",
      "Your branch is up to date with 'origin/development'.\n",
      "\n",
      "nothing to commit, working tree clean\n",
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "!git commit -a -m \"fixed implementations to be gpu and cpu consistent\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2c79e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch development\r\n",
      "Your branch is up to date with 'origin/development'.\r\n",
      "\r\n",
      "nothing to commit, working tree clean\r\n"
     ]
    }
   ],
   "source": [
    "!git status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae9eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7818c054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 'development' set up to track remote branch 'development' from 'origin'.\r\n",
      "Switched to a new branch 'development'\r\n"
     ]
    }
   ],
   "source": [
    "!git checkout development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced03e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrebate import MultiSURFstar as SKMultiSURF\n",
    "from skrebate import SURFstar as SURFSK\n",
    "from skrebate import ReliefF as ReliefFSK\n",
    "import numpy as np\n",
    "def generate_large_robust_dataset(n_samples=1000, seed=29):\n",
    "    np.random.seed(seed)\n",
    "    # Create balanced binary classes\n",
    "    n0 = n_samples // 2\n",
    "    n1 = n_samples - n0\n",
    "    y = np.array([0] * n0 + [1] * n1, dtype=np.int32)\n",
    "\n",
    "    # Feature 0: Highly relevant continuous feature.\n",
    "    # Class 0 samples come from N(1, 1), class 1 samples come from N(10, 1).\n",
    "    f0_class0 = np.random.normal(loc=1.0, scale=1.0, size=n0)\n",
    "    f0_class1 = np.random.normal(loc=10.0, scale=1.0, size=n1)\n",
    "    f0 = np.concatenate([f0_class0, f0_class1])\n",
    "\n",
    "    # Feature 1: Irrelevant noise feature.\n",
    "    # Values drawn from a standard normal distribution regardless of class.\n",
    "    f1 = np.random.normal(loc=0.0, scale=1.0, size=n_samples)\n",
    "\n",
    "    # Feature 2: Relevant discrete feature.\n",
    "    # Class 0 predominantly gets value 10 but with a small chance for 20,\n",
    "    # and class 1 predominantly gets value 20 but with a small chance for 10.\n",
    "    f2_class0 = np.random.choice([10, 20], size=n0, p=[0.9, 0.1])\n",
    "    f2_class1 = np.random.choice([20, 10], size=n1, p=[0.9, 0.1])\n",
    "    f2 = np.concatenate([f2_class0, f2_class1])\n",
    "\n",
    "    # Feature 3: Irrelevant constant feature.\n",
    "    f3 = np.full((n_samples,), 3.0)\n",
    "\n",
    "    # Assemble features into one array.\n",
    "    X = np.column_stack([f0, f1, f2, f3]).astype(np.float32)\n",
    "\n",
    "    # Shuffle the dataset (so the classes are randomly interleaved)\n",
    "    idx = np.arange(n_samples)\n",
    "    np.random.shuffle(idx)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "    return X, y\n",
    "\n",
    "X,y = generate_large_robust_dataset()\n",
    "model = SKMultiSURF()\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)\n",
    "model = SURFSK()\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)\n",
    "model = ReliefFSK()\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b388ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fast_select import MultiSURF, ReliefF, SURF\n",
    "import numpy as np\n",
    "def generate_large_robust_dataset(n_samples=10000, seed=59):\n",
    "    np.random.seed(seed)\n",
    "    # Create balanced binary classes\n",
    "    n0 = n_samples // 2\n",
    "    n1 = n_samples - n0\n",
    "    y = np.array([0] * n0 + [1] * n1, dtype=np.int32)\n",
    "\n",
    "    # Feature 0: Highly relevant continuous feature.\n",
    "    # Class 0 samples come from N(1, 1), class 1 samples come from N(10, 1).\n",
    "    f0_class0 = np.random.normal(loc=1.0, scale=1.0, size=n0)\n",
    "    f0_class1 = np.random.normal(loc=10.0, scale=1.0, size=n1)\n",
    "    f0 = np.concatenate([f0_class0, f0_class1])\n",
    "\n",
    "    # Feature 1: Irrelevant noise feature.\n",
    "    # Values drawn from a standard normal distribution regardless of class.\n",
    "    f1 = np.random.normal(loc=0.0, scale=1.0, size=n_samples)\n",
    "\n",
    "    # Feature 2: Relevant discrete feature.\n",
    "    # Class 0 predominantly gets value 10 but with a small chance for 20,\n",
    "    # and class 1 predominantly gets value 20 but with a small chance for 10.\n",
    "    f2_class0 = np.random.choice([10, 20], size=n0, p=[0.9, 0.1])\n",
    "    f2_class1 = np.random.choice([20, 10], size=n1, p=[0.9, 0.1])\n",
    "    f2 = np.concatenate([f2_class0, f2_class1])\n",
    "\n",
    "    # Feature 3: Irrelevant constant feature.\n",
    "    f3 = np.full((n_samples,), 3.0)\n",
    "\n",
    "    # Assemble features into one array.\n",
    "    X = np.column_stack([f0, f1, f2, f3]).astype(np.float32)\n",
    "\n",
    "    # Shuffle the dataset (so the classes are randomly interleaved)\n",
    "    idx = np.arange(n_samples)\n",
    "    np.random.shuffle(idx)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "    return X, y\n",
    "\n",
    "X,y = generate_large_robust_dataset()\n",
    "model = MultiSURF(discrete_limit=4, use_star=True)\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)\n",
    "X,y = generate_large_robust_dataset()\n",
    "model = MultiSURF(discrete_limit=4, backend='cpu', use_star=True)\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)\n",
    "model = ReliefF(discrete_limit=4)\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)\n",
    "model = ReliefF(discrete_limit=4, backend='cpu')\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)\n",
    "model = SURF(discrete_limit=4, use_star=True)\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)\n",
    "model = SURF(discrete_limit=4, backend='cpu', use_star=True)\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "946ed576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Runtime Plots ---\n",
      "Plot saved to 'benchmark_p_dominant_runtime.png'\n",
      "Plot saved to 'benchmark_n_dominant_runtime.png'\n",
      "\n",
      "--- Generating Memory Usage Plots ---\n",
      "Plot saved to 'benchmark_p_dominant_memory.png'\n",
      "Plot saved to 'benchmark_n_dominant_memory.png'\n"
     ]
    }
   ],
   "source": [
    "# plot_benchmarks.py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "def plot_scenario(df, scenario_name, x_axis, y_axis, y_label, title, filename, use_log_scale=True):\n",
    "    \"\"\"\n",
    "    Generic helper function to generate and save a plot for a given scenario.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The full results dataframe.\n",
    "        scenario_name (str): The name of the scenario to filter for (e.g., 'p >> n').\n",
    "        x_axis (str): The column name for the x-axis (e.g., 'n_features').\n",
    "        y_axis (str): The column name for the y-axis (e.g., 'runtime_sec').\n",
    "        y_label (str): The descriptive label for the y-axis.\n",
    "        title (str): The main title for the plot.\n",
    "        filename (str): The output filename for the saved plot.\n",
    "        use_log_scale (bool): Whether to use a logarithmic scale for the y-axis.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame for the specific scenario\n",
    "    scenario_df = df[df['scenario'] == scenario_name].copy()\n",
    "\n",
    "    # Create a new figure and axes for the plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Use seaborn for a clean, publication-quality line plot\n",
    "    sns.lineplot(\n",
    "        data=scenario_df,\n",
    "        x=x_axis,\n",
    "        y=y_axis,\n",
    "        hue='algorithm',\n",
    "        marker='o',\n",
    "        linewidth=2.5,\n",
    "        errorbar='sd' # 'ci' is deprecated; 'errorbar' is the new standard\n",
    "    )\n",
    "    \n",
    "    # Set plot properties\n",
    "    plt.title(title, fontsize=18, fontweight='bold', pad=20)\n",
    "    plt.xlabel(x_axis.replace('_', ' ').title(), fontsize=14)\n",
    "    plt.ylabel(y_label, fontsize=14)\n",
    "    \n",
    "    if use_log_scale:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
    "    plt.legend(title='Algorithm', fontsize=11, title_fontsize=13)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Plot saved to '{filename}'\")\n",
    "    plt.close() # Close the figure to free up memory\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to load results and generate all plots.\"\"\"\n",
    "    input_file = \"benchmark_results_with_memory.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(input_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: '{input_file}' not found.\", file=sys.stderr)\n",
    "        print(\"Please run the updated benchmark script first.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Validate that the necessary columns exist\n",
    "    required_cols = ['scenario', 'algorithm', 'n_samples', 'n_features', 'runtime_sec', 'peak_memory_mb']\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        print(f\"Error: The CSV file '{input_file}' is missing required columns.\", file=sys.stderr)\n",
    "        print(f\"Expected columns: {required_cols}\", file=sys.stderr)\n",
    "        print(f\"Found columns: {list(df.columns)}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Use a professional plot style\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    # --- Runtime Plots ---\n",
    "    print(\"\\n--- Generating Runtime Plots ---\")\n",
    "    plot_scenario(\n",
    "        df=df,\n",
    "        scenario_name='p >> n (Features Dominant)',\n",
    "        x_axis='n_features',\n",
    "        y_axis='runtime_sec',\n",
    "        y_label=\"Runtime (seconds, log scale)\",\n",
    "        title='Benchmark: Runtime vs. Number of Features (p >> n)\\n(n_samples fixed)',\n",
    "        filename='benchmark_p_dominant_runtime.png',\n",
    "        use_log_scale=True\n",
    "    )\n",
    "    plot_scenario(\n",
    "        df=df,\n",
    "        scenario_name='n >> p (Samples Dominant)',\n",
    "        x_axis='n_samples',\n",
    "        y_axis='runtime_sec',\n",
    "        y_label=\"Runtime (seconds, log scale)\",\n",
    "        title='Benchmark: Runtime vs. Number of Samples (n >> p)\\n(n_features fixed)',\n",
    "        filename='benchmark_n_dominant_runtime.png',\n",
    "        use_log_scale=True\n",
    "    )\n",
    "\n",
    "    # --- Memory Usage Plots ---\n",
    "    print(\"\\n--- Generating Memory Usage Plots ---\")\n",
    "    plot_scenario(\n",
    "        df=df,\n",
    "        scenario_name='p >> n (Features Dominant)',\n",
    "        x_axis='n_features',\n",
    "        y_axis='peak_memory_mb',\n",
    "        y_label=\"Peak Memory Usage (MB, log scale)\",\n",
    "        title='Benchmark: Memory vs. Number of Features (p >> n)\\n(n_samples fixed)',\n",
    "        filename='benchmark_p_dominant_memory.png',\n",
    "        use_log_scale=True # Memory can also vary greatly, log scale is often useful\n",
    "    )\n",
    "    plot_scenario(\n",
    "        df=df,\n",
    "        scenario_name='n >> p (Samples Dominant)',\n",
    "        x_axis='n_samples',\n",
    "        y_axis='peak_memory_mb',\n",
    "        y_label=\"Peak Memory Usage (MB, log scale)\",\n",
    "        title='Benchmark: Memory vs. Number of Samples (n >> p)\\n(n_features fixed)',\n",
    "        filename='benchmark_n_dominant_memory.png',\n",
    "        use_log_scale=True\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4adc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
